{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a86fe262-b2b3-48cf-b8ed-c4409648a78f",
      "metadata": {
        "id": "a86fe262-b2b3-48cf-b8ed-c4409648a78f"
      },
      "source": [
        "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 2: DPO –∏ PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e70aa25-a6f3-4d56-b648-3da1b89c0c51",
      "metadata": {
        "id": "2e70aa25-a6f3-4d56-b648-3da1b89c0c51"
      },
      "source": [
        "–í —ç—Ç–æ–π –¥–æ–º–∞—à–∫–µ –ø–æ–±–ª–∏–∂–µ –ø–æ–∑–Ω–∞–∫–æ–º–∏–º—Å—è —Å –¥–≤—É–º—è –∫—Ä–∞–π–Ω–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∞–ª–∞–π–º–µ–Ω—Ç–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –í –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –≤–∞–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –∑–∞–∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ç—å DPO c –Ω—É–ª—è. –í–æ –≤—Ç–æ—Ä–æ–π —á–∞—Å—Ç–∏ –º—ã —É–∂–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É TRL –∏ –æ–±—É—á–∏–º PPO.\n",
        "\n",
        "–û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∏ –Ω—É–∂–Ω–æ –≤—ã–ª–æ–∂–∏—Ç—å –Ω–∞ [ü§ó HuggingFace](https://huggingface.co/). –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å —Ç–∞–º, –ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –Ω–∞ [deep vk](https://huggingface.co/deepvk) –∏ —Å–æ–∑–¥–∞–π—Ç–µ —Å–µ–±–µ API —Ç–æ–∫–µ–Ω.\n",
        "\n",
        "–°–ª–µ–¥—É–π—Ç–µ —è—á–µ–π–∫–∞–º —Ç–µ—Ç—Ä–∞–¥–∫–∏ –∏ –∑–∞–ø–æ–ª–Ω—è–π—Ç–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏. –í –∫–æ–Ω—Ü–µ —Ç–µ—Ç—Ä–∞–¥–∫–∏ –≤—ã –Ω–∞–π–¥–µ—Ç–µ –∑–∞–¥–∞—á–∏ —Å–æ –∑–≤–µ–∑–¥–æ—á–∫–æ–π, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34db04f4-5870-4b32-8ed0-5a8d8733f0bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-15T18:56:01.716457Z",
          "iopub.status.busy": "2025-03-15T18:56:01.716028Z",
          "iopub.status.idle": "2025-03-15T18:56:01.720243Z",
          "shell.execute_reply": "2025-03-15T18:56:01.719321Z",
          "shell.execute_reply.started": "2025-03-15T18:56:01.716420Z"
        },
        "id": "34db04f4-5870-4b32-8ed0-5a8d8733f0bd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# colab_llm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a223a0b-6896-49f6-a5cf-0edc0984595b",
      "metadata": {
        "id": "6a223a0b-6896-49f6-a5cf-0edc0984595b"
      },
      "source": [
        "## –ò–º–ø–æ—Ä—Ç—ã –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "79504930-ceac-42a3-8d43-3f2fe4e7a5d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T21:32:23.146435Z",
          "iopub.status.busy": "2025-03-28T21:32:23.146096Z",
          "iopub.status.idle": "2025-03-28T21:32:27.865279Z",
          "shell.execute_reply": "2025-03-28T21:32:27.864477Z",
          "shell.execute_reply.started": "2025-03-28T21:32:23.146409Z"
        },
        "id": "79504930-ceac-42a3-8d43-3f2fe4e7a5d4",
        "outputId": "e3009120-d950-4134-c7fd-b5e54777cfc6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m481.3/491.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# –£—Å—Ç–∞–Ω–æ–≤–∏–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "\n",
        "%pip install --quiet datasets trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1369a8cc-b9a4-4a52-a4df-a15489ea3352",
      "metadata": {
        "editable": true,
        "execution": {
          "iopub.execute_input": "2025-03-28T21:32:27.866692Z",
          "iopub.status.busy": "2025-03-28T21:32:27.866455Z",
          "iopub.status.idle": "2025-03-28T21:32:51.803154Z",
          "shell.execute_reply": "2025-03-28T21:32:51.802291Z",
          "shell.execute_reply.started": "2025-03-28T21:32:27.866671Z"
        },
        "id": "1369a8cc-b9a4-4a52-a4df-a15489ea3352",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã (–¥–ª—è –æ–±–æ–∏—Ö —á–∞—Å—Ç–µ–π)\n",
        "import inspect\n",
        "import random\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import HfApi, interpreter_login\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedTokenizerBase,\n",
        ")\n",
        "from trl import PPOConfig, PPOTrainer, RewardConfig, RewardTrainer\n",
        "\n",
        "import time\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0a8464f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T21:32:51.805633Z",
          "iopub.status.busy": "2025-03-28T21:32:51.804996Z",
          "iopub.status.idle": "2025-03-28T21:32:55.479583Z",
          "shell.execute_reply": "2025-03-28T21:32:55.478676Z",
          "shell.execute_reply.started": "2025-03-28T21:32:51.805607Z"
        },
        "id": "0a8464f5",
        "outputId": "2973cab8-4465-4bf3-dc08-20b3e5bc0ab1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your token (input will not be visible): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Add token as git credential? (Y/n) Y\n"
          ]
        }
      ],
      "source": [
        "interpreter_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "roN_8L5BsTLD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roN_8L5BsTLD",
        "outputId": "6200256c-e63f-4658-9909-53772ba236dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7ce75b35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T21:32:55.480812Z",
          "iopub.status.busy": "2025-03-28T21:32:55.480576Z",
          "iopub.status.idle": "2025-03-28T21:32:55.523567Z",
          "shell.execute_reply": "2025-03-28T21:32:55.522929Z",
          "shell.execute_reply.started": "2025-03-28T21:32:55.480792Z"
        },
        "id": "7ce75b35",
        "outputId": "7ba0061d-585d-496f-d698-c4051b5d1c39",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Homework repository: 'Dayara13/llm-course-hw2'\n"
          ]
        }
      ],
      "source": [
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è –±—É–¥—É—â–µ–π –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
        "username = HfApi().whoami()[\"name\"]\n",
        "REPO_NAME = f\"{username}/llm-course-hw2\"  # –ò–ª–∏ –∫–∞–∫ –≤–∞–º —Ö–æ—á–µ—Ç—Å—è\n",
        "\n",
        "print(f\"Homework repository: '{REPO_NAME}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fa23203d-233f-4a30-aa5a-8ee669275caf",
      "metadata": {
        "editable": true,
        "execution": {
          "iopub.execute_input": "2025-03-28T21:32:55.524506Z",
          "iopub.status.busy": "2025-03-28T21:32:55.524273Z",
          "iopub.status.idle": "2025-03-28T21:32:55.529263Z",
          "shell.execute_reply": "2025-03-28T21:32:55.528404Z",
          "shell.execute_reply.started": "2025-03-28T21:32:55.524482Z"
        },
        "id": "fa23203d-233f-4a30-aa5a-8ee669275caf",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "# –≠—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π –±—É–¥—É—Ç –ø–æ–º–µ—á–µ–Ω—ã –≤—Å–µ –º–µ—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–∑–∞–ø–æ–ª–Ω–∏—Ç—å\n",
        "# –≠—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞–∫ —Ü–µ–ª—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, —Ç–∞–∫ –∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –Ω–∏—Ö\n",
        "# –í—Å–µ–≥–¥–∞ –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏–Ω—Ç—Ä–æ—Å–ø–µ–∫—Ü–∏–µ–π –∏ –Ω–∞–π—Ç–∏ –º–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ :)\n",
        "def todo():\n",
        "    stack = inspect.stack()\n",
        "    caller_frame = stack[1]\n",
        "    function_name = caller_frame.function\n",
        "    line_number = caller_frame.lineno\n",
        "    raise NotImplementedError(f\"TODO at {function_name}, line {line_number}\")\n",
        "\n",
        "\n",
        "def disable_dropout_in_model(model):\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, torch.nn.Dropout):\n",
        "            module.p = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8e36c1d-6e89-4643-a0bb-1a1c916c3466",
      "metadata": {
        "editable": true,
        "id": "e8e36c1d-6e89-4643-a0bb-1a1c916c3466",
        "tags": []
      },
      "source": [
        "# –ß–∞—Å—Ç—å 1: DPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ae081e-f2f6-4790-b239-a6ec1c0db1f2",
      "metadata": {
        "id": "b2ae081e-f2f6-4790-b239-a6ec1c0db1f2"
      },
      "source": [
        "–ö—Ä–∞–π–Ω–µ –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≤ —Å–≤–æ–µ –≤—Ä–µ–º—è –ø—Ä–æ–∏–∑–≤–µ–ª —Ñ—É—Ä–æ—Ä, —Ç.–∫. –≤—ã–≥–æ–¥–Ω–æ –≤—ã–¥–µ–ª—è–ª—Å—è –Ω–∞ —Ñ–æ–Ω–µ PPO. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç PPO, —Ç—Ä–µ–±—É—é—â–µ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ –æ–±—É—á–∞—Ç—å Reward Model, Value Model –∏ –±–æ–ª—å—à–∏—Ö —É—Å–∏–ª–∏–π –≤ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏, DPO –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —è–≤–Ω–æ–π —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª–∏, –∞ —Ç–æ–ª—å–∫–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º–∏ –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º–∏ –≤–∏–¥–∞: –ø—Ä–æ–º–ø—Ç, –≤—ã–±—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º –æ—Ç–≤–µ—Ç, –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º –æ—Ç–≤–µ—Ç. –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ç–∞–∫–∂–µ –≤–∏–¥–Ω–∞ –∏–∑ –ª–æ—Å—Å–∞, –ø–æ —Å—É—Ç–∏ —ç—Ç–æ –≤–µ—Å—å –º–µ—Ç–æ–¥:\n",
        "$$\n",
        "L_\\text{DPO}(\\pi_{\\theta}; \\pi_\\text{ref}) = -E_{(x, y_w, y_l)\\sim D}\\left[\\log \\sigma \\left(\n",
        "\\beta \\log \\frac{\\pi_{\\theta}(y_w\\mid x)}{\\pi_\\text{ref}(y_w\\mid x)} \\thinspace\n",
        "{- \\beta \\log \\frac{\\pi_{\\theta}(y_l\\mid x)}{\\pi_\\text{ref}(y_l\\mid x)}}\\right)\\right]\n",
        "$$\n",
        "\n",
        "–≥–¥–µ:\n",
        "\n",
        "- $\\pi_{\\theta}$ LLM –∫–æ—Ç–æ—Ä—É—é –º—ã —Ö–æ—Ç–∏–º –∑–∞–∞–ª–∞–π–Ω–∏—Ç—å\n",
        "- $\\pi_\\text{ref}$ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞—á–∞–ª—å–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç\n",
        "- $D$ –¥–∞—Ç–∞—Å–µ—Ç —Å –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º–∏\n",
        "- $x$ –ø—Ä–æ–º–ø—Ç –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ $D$\n",
        "- $y_w$ –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–æ–º–ø—Ç $x$ –≤—ã–±—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º (–∏–ª–∏ —Ç–µ–º –∫—Ç–æ —Ä–∞–∑–º–µ—á–∞–ª –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –±–æ–ª—å—à–∞—è LLM)\n",
        "- $y_l$ –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–æ–º–ø—Ç $x$ –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º (–∏–ª–∏ —Ç–µ–º –∫—Ç–æ —Ä–∞–∑–º–µ—á–∞–ª –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –±–æ–ª—å—à–∞—è LLM)\n",
        "- $\\beta$ –≥–∏–ø–µ—Ä–µ–ø–∞—Ä–∞–º–µ—Ç—Ä –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ —Ç–æ, –∫–∞–∫ –¥–∞–ª–µ–∫–æ –º—ã –º–æ–∂–µ–º –æ—Ç—Ö–æ–¥–∏—Ç—å –æ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "\n",
        "–í–æ –≤—Ä–µ–º—è –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–æ–≤–µ—Ç—É–º –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é: [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290).\n",
        "\n",
        "–î–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∞ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å [HuggingFaceTB/SmolLM-135M-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM-135M-Instruct), —Ç.–∫. –æ–Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (–ø–æ–º–µ—Å—Ç–∏—Ç—Å—è –Ω–∞ Colab), –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º —É–º–µ–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç –∞–ª–∞–π–º–µ–Ω—Ç–∞. –ë–æ–ª–µ–µ —Ç–æ–≥–æ, –¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–∞–∂–µ –ø—Ä–æ—à–ª–∞ —Å—Ç–∞–¥–∏—é SFT, –∞ –ø–æ—ç—Ç–æ–º—É –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (–±–µ–∑ Instruct) –ø–æ–Ω–∏–º–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç —á–∞—Ç–∞ (chat-template –≤ transformers, –¥–∞–ª—å—à–µ —Ä–∞–∑–±–µ—Ä–µ–º) –∏ –∏–º–µ–µ—Ç '–æ—Å–æ–∑–Ω–∞–Ω–∏–µ' —Å–µ–±—è —è–∑—ã–∫–æ–≤—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.\n",
        "\n",
        "P.S. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º —Ç–∏–ø–æ A100 –∏ –±–æ–ª—å—à–µ, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞—Ñ–∞–π–Ω—Ç—é–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑ —ç—Ç–æ–π –∂–µ [–ª–∏–Ω–µ–π–∫–∏](https://huggingface.co/blog/smollm). –ë—É–¥—å—Ç–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã, —Å–º–æ—Ç—Ä–∏—Ç–µ, —á—Ç–æ–±—ã –æ–Ω–∞ –±—ã–ª–∞ —Å –¥–æ–±–∞–≤–∫–æ–π Instruct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3d88765f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T21:32:55.530382Z",
          "iopub.status.busy": "2025-03-28T21:32:55.530090Z",
          "iopub.status.idle": "2025-03-28T21:32:55.541353Z",
          "shell.execute_reply": "2025-03-28T21:32:55.540578Z",
          "shell.execute_reply.started": "2025-03-28T21:32:55.530356Z"
        },
        "id": "3d88765f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
        "DATASET_ID = \"HumanLLMs/Human-Like-DPO-Dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9004f808-b6bc-46fe-bc77-f7d4e381f963",
      "metadata": {
        "id": "9004f808-b6bc-46fe-bc77-f7d4e381f963"
      },
      "source": [
        "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö [2 –±–∞–ª–ª–∞]\n",
        "\n",
        "–î–ª—è –Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [HumanLLMs/Human-Like-DPO-Dataset](https://huggingface.co/datasets/HumanLLMs/Human-Like-DPO-Dataset), –∫–æ—Ç–æ—Ä—ã–π –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —ç–º–æ–¥–∑–∏ –∏ –≤ —Ü–µ–ª–æ–º —Å–Ω–∏–∂–∞–µ—Ç —Å—Ç—Ä–æ–≥–æ—Å—Ç—å —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —à–∞–±–ª–æ–Ω—É \"As a conversational AI, I ...\".\n",
        "\n",
        "–ß—Ç–æ–±—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –Ω—É–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã—Ö —ç—Ç–∞–ø–æ–≤:\n",
        "1. –ü—Ä–∏–≤–µ—Å—Ç –¥–∞–Ω–Ω—ã–µ –∫ —Ñ–æ—Ä–º–∞—Ç—É chat-template\n",
        "2. –ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —ç—Ç–æ—Ç chat-template —Å –ø–æ–º–æ—â—å—é 'tokenizer.apply_chat_template'\n",
        "3. –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∏–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ, –ø–æ–ø—É—Ç–Ω–æ –æ–±—Ä–µ–∑–∞–≤ –ø—Ä–æ–º–ø—Ç –∏ –æ—Ç–≤–µ—Ç—ã –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏–Ω—ã, –µ—Å–ª–∏ –Ω–∞–¥–æ.\n",
        "\n",
        "–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π—Ç–µ [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ chat-templates](https://huggingface.co/docs/transformers/chat_templating). –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –≤ –Ω–∞—á–∞–ª–µ –≤ –±–æ–ª–µ–µ –≤–µ—Ä—Ö–Ω–µ-—É—Ä–æ–≤–Ω–µ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–∞–∫–æ–≥–æ –≤–∏–¥–∞:\n",
        "```python\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant focused on technical topics.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you explain what a chat template is?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"A chat template structures conversations between users and AI models...\"}\n",
        "]\n",
        "```\n",
        "–¢–æ –µ—Å—Ç—å –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ä–æ–ª–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ –Ω–∞–ø—Ä–∏–º–µ—Ä —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∏ –≤ —Ü–µ–ª–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –∏ —á–µ–ª–æ–≤–µ–∫–æ–º. –û–±—ã—á–Ω–æ –æ–±—É—á–µ–Ω–∏–µ —ç—Ç–æ–º—É –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —ç—Ç–∞–ø–µ SFT. –î–∞–Ω–Ω–∞—è —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –∞–±—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã) –∫–∞–∫ —ç—Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏. –ß—Ç–æ–±—ã –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –µ–≥–æ –≤ –Ω–µ—Å–ø–æ—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∏–Ω–ø—É—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `tokenizer.apply_chat_template`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "553b75fe-e0b2-4c68-9c1e-9b2d58983da6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T20:53:11.268769Z",
          "iopub.status.busy": "2025-03-28T20:53:11.268349Z",
          "iopub.status.idle": "2025-03-28T20:53:13.254503Z",
          "shell.execute_reply": "2025-03-28T20:53:13.253476Z",
          "shell.execute_reply.started": "2025-03-28T20:53:11.268733Z"
        },
        "id": "553b75fe-e0b2-4c68-9c1e-9b2d58983da6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "aa5e40e1-94a3-4ed9-8f33-1bd45fa9086d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T20:53:13.257307Z",
          "iopub.status.busy": "2025-03-28T20:53:13.256895Z",
          "iopub.status.idle": "2025-03-28T20:53:16.509322Z",
          "shell.execute_reply": "2025-03-28T20:53:16.508160Z",
          "shell.execute_reply.started": "2025-03-28T20:53:13.257265Z"
        },
        "id": "aa5e40e1-94a3-4ed9-8f33-1bd45fa9086d",
        "outputId": "06b3230a-d3cf-4847-c069-bf59ecdc2abb",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'Oh, I just saw the best meme - have you seen it?',\n",
              " 'chosen': \"üòÇ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ü§£\",\n",
              " 'rejected': \"I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?\"}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565dcc5d-8e70-4917-97b8-ed8c7f08d964",
      "metadata": {
        "id": "565dcc5d-8e70-4917-97b8-ed8c7f08d964"
      },
      "source": [
        "–ü—Ä–∏–≤–µ–¥–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –∫ —Ñ–æ—Ä–º–∞—Ç—É —á–∞—Ç–∞, –≥–¥–µ —É –ø—Ä–æ–º–ø—Ç–∞ —Ä–æ–ª—å user, –∞ —É –æ—Ç–≤–µ—Ç–æ–≤ assistant, –∞ –ø–æ—Ç–æ–º –ø—Ä–∏–º–µ–Ω–∏—Ç–µ —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "6e06515d-abdc-4b3f-b4eb-b7b00c922bff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T20:53:26.477027Z",
          "iopub.status.busy": "2025-03-28T20:53:26.476619Z",
          "iopub.status.idle": "2025-03-28T20:53:26.483738Z",
          "shell.execute_reply": "2025-03-28T20:53:26.482420Z",
          "shell.execute_reply.started": "2025-03-28T20:53:26.476997Z"
        },
        "id": "6e06515d-abdc-4b3f-b4eb-b7b00c922bff",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def apply_chat_template(example: dict[str, str], tokenizer: PreTrainedTokenizerBase) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    Transforms a dataset example into a formatted chat template using the provided tokenizer.\n",
        "\n",
        "    Args:\n",
        "        example (Dict[str, str]): A dictionary containing the following keys:\n",
        "            - \"prompt\": The initial user prompt.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "        tokenizer (PreTrainedTokenizerBase): An object that provides the `apply_chat_template` method\n",
        "            for formatting the conversation.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, str]: A dictionary with the following keys:\n",
        "            - \"prompt\": The formatted prompt string including the generation prompt.\n",
        "            - \"chosen\": The formatted assistant's chosen response (with the prompt prefix removed).\n",
        "            - \"rejected\": The formatted assistant's rejected response (with the prompt prefix removed).\n",
        "    \"\"\"\n",
        "    # todo()\n",
        "    chat_template = [\n",
        "        {'role': 'user', 'content': example['prompt']},\n",
        "        {'role': 'assistant', 'content': example['chosen']},\n",
        "        {'role': 'assistant', 'content': example['rejected']}\n",
        "    ]\n",
        "    chat_template_modif = tokenizer.apply_chat_template(\n",
        "        chat_template, tokenize=False,\n",
        "    )\n",
        "    assistant_div = \"<|im_start|>assistant\\n\"\n",
        "    parts = chat_template_modif.split(assistant_div)\n",
        "    result = {\n",
        "        'prompt': parts[0] + assistant_div,\n",
        "        'chosen': parts[1],\n",
        "        'rejected': parts[2],\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "fcb16881-c63a-41ae-b5ed-9a37b62a98ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T20:53:28.323365Z",
          "iopub.status.busy": "2025-03-28T20:53:28.323029Z",
          "iopub.status.idle": "2025-03-28T20:53:30.297920Z",
          "shell.execute_reply": "2025-03-28T20:53:30.296849Z",
          "shell.execute_reply.started": "2025-03-28T20:53:28.323339Z"
        },
        "id": "fcb16881-c63a-41ae-b5ed-9a37b62a98ff",
        "outputId": "23e2b87e-dc01-4c6c-90c5-19ccf360244d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': '<|im_start|>user\\nOh, I just saw the best meme - have you seen it?<|im_end|>\\n<|im_start|>assistant\\n',\n",
              " 'chosen': \"üòÇ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ü§£<|im_end|>\\n\",\n",
              " 'rejected': \"I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?<|im_end|>\\n\"}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer})\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b64dabac-883f-41db-b6d8-9fff5ae32d35",
      "metadata": {
        "id": "b64dabac-883f-41db-b6d8-9fff5ae32d35"
      },
      "source": [
        "–ü–æ—Å–ª–µ —ç—Ç–∏—Ö –¥–≤—É—Ö —ç—Ç–∞–ø–æ–≤ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫ (**–æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –ø–æ–ª–æ–∂–µ–Ω–∏–µ <|im_start|>assistant\\n**, —ç—Ç–æ –≤–∞–∂–Ω–æ!):\n",
        "```\n",
        "{\n",
        "    'prompt': \"<|im_start|>user\\nOh, I just saw the best meme - have you seen it <|im_end|>\\n<|im_start|>assistant\\n\",\n",
        "    'chosen': \"üòÇ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ü§£<|im_end|>\\n\",\n",
        "    'rejected': \"I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?<|im_end|>\\n\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a94b01",
      "metadata": {
        "id": "a3a94b01"
      },
      "source": [
        "–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –ø–æ–º–æ—â—å—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞, –æ–±—Ä–µ–∑–∞–≤ –¥–ª–∏–Ω—É –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ. –í –¥–∞—Ç–∞—Å–µ—Ç–µ –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ ID —Ç–æ–∫–µ–Ω–æ–≤:\n",
        "```\n",
        "Dataset({\n",
        "    features: ['prompt_input_ids', 'chosen_input_ids', 'rejected_input_ids'],\n",
        "    num_rows: 10884\n",
        "})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ad02508-e4f9-43fa-a3e6-7ecd0e2963df",
      "metadata": {
        "id": "8ad02508-e4f9-43fa-a3e6-7ecd0e2963df"
      },
      "source": [
        "–û–±—Ä–µ–∑–∞–π—Ç–µ –ø—Ä–æ–º–ø—Ç —Å–ª–µ–≤–∞, –∞ –Ω–µ —Å –∫–æ–Ω—Ü–∞. –ü–æ–¥—É–º–∞–π—Ç–µ –ø–æ—á–µ–º—É —Ç–∞–∫ –ª—É—á—à–µ. **–ù–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ–π –æ—Ç–≤–µ—Ç**.\n",
        "\n",
        "    #========== TODO ==========\n",
        "    –î–ª—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –æ–±—ã—á–Ω–æ –∏–∑–≤–ª–µ—á—å –∫—É–¥–∞ –±–æ–ª—å—à—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ü–∞ –ø—Ä–æ–º–ø—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, –∫–∞–∫ –µ–π –ª—É—á—à–µ –æ—Ç–≤–µ—Ç–∏—Ç—å\n",
        "    –¢–∞–∫ –∂–µ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Ç–æ–≥–æ –∂–µ DPO –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞ –∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏, —Ç–æ –µ—Å—Ç—å, –ø—Ä–∏ –æ–±—Ä–µ–∑–∞–Ω–∏–∏ –ø—Ä–æ–º–ø—Ç–∞ —Å –∫–æ–Ω—Ü–∞ –±—É–¥–µ—Ç —Å–º—ã—Å–ª–æ–≤–æ–π —Ä–∞–∑—Ä—ã–≤ –ø–æ —Ç–µ–∫—Å—Ç—É –ø–æ—Å–ª–µ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏\n",
        "    #=========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "ab86a8b4-ba29-442b-92a9-294a9153cfe8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T20:54:17.615011Z",
          "iopub.status.busy": "2025-03-28T20:54:17.614581Z",
          "iopub.status.idle": "2025-03-28T20:54:17.621973Z",
          "shell.execute_reply": "2025-03-28T20:54:17.620645Z",
          "shell.execute_reply.started": "2025-03-28T20:54:17.614978Z"
        },
        "id": "ab86a8b4-ba29-442b-92a9-294a9153cfe8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def tokenize_row(\n",
        "    example: dict[str, str],\n",
        "    tokenizer: PreTrainedTokenizerBase,\n",
        "    max_prompt_length: int = 512,\n",
        "    max_completion_length: int | None = None,\n",
        ") -> dict[str, list[int]]:\n",
        "    \"\"\"\n",
        "    Tokenizes a single row of a dataset example for use in language model training or evaluation.\n",
        "\n",
        "    This function processes an example containing textual fields for a prompt, a chosen response,\n",
        "    and a rejected response. It tokenizes each text field using the provided tokenizer. If specified,\n",
        "    it truncates the tokenized prompt to the last `max_prompt_length` tokens and the tokenized responses\n",
        "    (chosen and rejected) to the first `max_completion_length` tokens.\n",
        "\n",
        "    Args:\n",
        "        example (dict[str, str]): A dictionary with the following keys:\n",
        "            - \"prompt\": The initial prompt text.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "        tokenizer (PreTrainedTokenizerBase): A tokenizer that converts text into token IDs. It must return a dictionary\n",
        "            with the key \"input_ids\" when called.\n",
        "        max_prompt_length (Optional[int], optional): Maximum number of tokens to retain for the prompt.\n",
        "            The function keeps the last `max_prompt_length` tokens. Defaults to 512.\n",
        "        max_completion_length (Optional[int], optional): Maximum number of tokens to retain for the completion\n",
        "            responses (chosen and rejected). The function keeps the first `max_completion_length` tokens.\n",
        "            If None, no truncation is applied. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, list[int]]: A dictionary containing:\n",
        "            - \"prompt_input_ids\": The token IDs for the prompt, possibly truncated.\n",
        "            - \"chosen_input_ids\": The token IDs for the chosen response, possibly truncated.\n",
        "            - \"rejected_input_ids\": The token IDs for the rejected response, possibly truncated.\n",
        "    \"\"\"\n",
        "    # todo()\n",
        "    tok_simple = partial(tokenizer, add_special_tokens=False)\n",
        "    prompt_input_ids = tok_simple(example['prompt'])['input_ids'][-max_prompt_length:]\n",
        "    chosen_input_ids = tok_simple(example['chosen'])['input_ids']\n",
        "    rejected_input_ids = tok_simple(example['rejected'])['input_ids']\n",
        "    if max_completion_length is not None:\n",
        "        rejected_input_ids = rejected_input_ids[:max_completion_length]\n",
        "        chosen_input_ids = chosen_input_ids[:max_completion_length]\n",
        "    result = {\n",
        "        'prompt_input_ids': prompt_input_ids,\n",
        "        'chosen_input_ids': chosen_input_ids,\n",
        "        'rejected_input_ids': rejected_input_ids,\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "902b567f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T20:54:18.851880Z",
          "iopub.status.busy": "2025-03-28T20:54:18.851428Z",
          "iopub.status.idle": "2025-03-28T20:54:43.750084Z",
          "shell.execute_reply": "2025-03-28T20:54:43.748889Z",
          "shell.execute_reply.started": "2025-03-28T20:54:18.851848Z"
        },
        "id": "902b567f",
        "outputId": "6788d35b-f0a6-43ab-e59a-89ce75a6aa3b",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt_input_ids': [1,\n",
              "  4093,\n",
              "  198,\n",
              "  16912,\n",
              "  28,\n",
              "  339,\n",
              "  915,\n",
              "  3680,\n",
              "  260,\n",
              "  1450,\n",
              "  1169,\n",
              "  85,\n",
              "  731,\n",
              "  457,\n",
              "  346,\n",
              "  2269,\n",
              "  357,\n",
              "  47,\n",
              "  2,\n",
              "  198,\n",
              "  1,\n",
              "  520,\n",
              "  9531,\n",
              "  198],\n",
              " 'chosen_input_ids': [10813,\n",
              "  242,\n",
              "  220,\n",
              "  12947,\n",
              "  28,\n",
              "  787,\n",
              "  339,\n",
              "  8540,\n",
              "  982,\n",
              "  17,\n",
              "  339,\n",
              "  5248,\n",
              "  11888,\n",
              "  288,\n",
              "  699,\n",
              "  28,\n",
              "  732,\n",
              "  506,\n",
              "  260,\n",
              "  1169,\n",
              "  85,\n",
              "  563,\n",
              "  47,\n",
              "  1431,\n",
              "  357,\n",
              "  253,\n",
              "  17025,\n",
              "  2644,\n",
              "  355,\n",
              "  253,\n",
              "  31404,\n",
              "  3223,\n",
              "  47,\n",
              "  1691,\n",
              "  388,\n",
              "  260,\n",
              "  9973,\n",
              "  17,\n",
              "  15107,\n",
              "  114,\n",
              "  113,\n",
              "  2,\n",
              "  198],\n",
              " 'rejected_input_ids': [57,\n",
              "  5248,\n",
              "  354,\n",
              "  6416,\n",
              "  5290,\n",
              "  1789,\n",
              "  1743,\n",
              "  28,\n",
              "  339,\n",
              "  1326,\n",
              "  982,\n",
              "  457,\n",
              "  2143,\n",
              "  2647,\n",
              "  355,\n",
              "  8428,\n",
              "  30,\n",
              "  1423,\n",
              "  28,\n",
              "  339,\n",
              "  416,\n",
              "  1538,\n",
              "  346,\n",
              "  351,\n",
              "  1096,\n",
              "  335,\n",
              "  3452,\n",
              "  29,\n",
              "  3119,\n",
              "  284,\n",
              "  9603,\n",
              "  32246,\n",
              "  9411,\n",
              "  28,\n",
              "  347,\n",
              "  876,\n",
              "  347,\n",
              "  7400,\n",
              "  1552,\n",
              "  335,\n",
              "  1678,\n",
              "  14009,\n",
              "  355,\n",
              "  5535,\n",
              "  30,\n",
              "  13651,\n",
              "  346,\n",
              "  702,\n",
              "  549,\n",
              "  288,\n",
              "  1820,\n",
              "  634,\n",
              "  7703,\n",
              "  10026,\n",
              "  355,\n",
              "  1692,\n",
              "  253,\n",
              "  1542,\n",
              "  10265,\n",
              "  282,\n",
              "  1384,\n",
              "  47,\n",
              "  2,\n",
              "  198]}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = dataset.map(\n",
        "    tokenize_row,\n",
        "    fn_kwargs={\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"max_prompt_length\": 256,\n",
        "        \"max_completion_length\": None,\n",
        "    },\n",
        "    remove_columns=[\"prompt\", \"chosen\", \"rejected\"],\n",
        ")\n",
        "\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e6687c2-73a7-4ae9-972c-6603673e6401",
      "metadata": {
        "id": "4e6687c2-73a7-4ae9-972c-6603673e6401"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –Ω–∞–¥–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å DataLoader. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–¥–æ –Ω–∞–ø–∏—Å–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π `collate_fn` –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ:\n",
        "1. –ü—Ä–∏–Ω–∏–º–∞—Ç—å –ª–∏—Å—Ç –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –∫–ª—é—á–∞–º–∏ `prompt_input_ids`, `chosen_input_ids`, `rejected_input_ids`.\n",
        "2. –ü–∞–¥–¥–∏—Ç—å –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤ –±–∞—Ç—á–µ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª—é—á—É. –ü–æ –∏—Ç–æ–≥—É `prompt_input_ids` –∏ `chosen_input_ids` –º–æ–≥—É—Ç –∏–º–µ—Ç—å —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –í–∞–∂–Ω–æ, —á—Ç–æ–±—ã –≤–Ω—É—Ç—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∫–ª—é—á–µ–π –¥–ª–∏–Ω–∞ –±—ã–ª–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞.\n",
        "3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–∞–¥–¥–∏–Ω–≥ –º–∞—Å–∫—É —Ç–∞–∫–æ–≥–æ –∂–µ —à–µ–π–ø–∞, –≥–¥–µ 0 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–∞–¥–¥–∏–Ω–≥-—Ç–æ–∫–µ–Ω–æ–≤ –∏ 1 –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
        "\n",
        "–î–ª—è –ø–∞–¥–¥–∏–Ω–≥–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `pad`. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ç–æ–∫–µ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `tokenizer.pad_token_id` –∏ 0 –¥–ª—è –º–∞—Å–∫–∏. **–û–ø—è—Ç—å –∂–µ, –ø–æ–¥—É–º–∞–π—Ç–µ –æ—Ç–∫—É–¥–∞ –ª—É—á—à–µ –ø–∞–¥–¥–∏—Ç—å `prompt_input_ids`?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "90431c77-694c-446b-bced-eae8124936fb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T20:57:52.247992Z",
          "iopub.status.busy": "2025-03-28T20:57:52.247498Z",
          "iopub.status.idle": "2025-03-28T20:57:52.261057Z",
          "shell.execute_reply": "2025-03-28T20:57:52.260033Z",
          "shell.execute_reply.started": "2025-03-28T20:57:52.247956Z"
        },
        "id": "90431c77-694c-446b-bced-eae8124936fb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def pad(tensors: list[torch.Tensor], padding_value: int = 0, padding_side: str = \"right\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Pads a list of tensors to the same size along their leading dimension.\n",
        "\n",
        "    Args:\n",
        "        tensors (list[torch.Tensor]): A list of tensors to be padded.\n",
        "            All tensors in the list should be of the same type and device.\n",
        "        padding_value (int, default=0): The value used to pad the tensors.\n",
        "        padding_side (str, default=\"right\"): Specifies which side of the tensor to apply padding: either 'left' or 'right'.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor containing all the padded tensors, [N; max_length]\n",
        "            where N is the number of tensors and `max_length` is the shape of the largest tensor.\n",
        "    \"\"\"\n",
        "    # todo()\n",
        "    assert padding_side in ['right', 'left']\n",
        "    if len(tensors[0].shape) == 1:\n",
        "        tensors = list(map(lambda x: x.unsqueeze(0), tensors))\n",
        "    max_len = max(map(lambda x: x.shape[1], tensors))\n",
        "    tensors_padded = list()\n",
        "    for tsr in tensors:\n",
        "        diff_size = max_len - tsr.shape[1]\n",
        "        if diff_size > 0:\n",
        "            fill_tensor = torch.full((1, diff_size), padding_value, dtype=torch.int)\n",
        "            if padding_side == 'right':\n",
        "                tensors_padded.append(torch.hstack((tsr, fill_tensor)))\n",
        "            else:\n",
        "                tensors_padded.append(torch.hstack((fill_tensor, tsr)))\n",
        "        else:\n",
        "            tensors_padded.append(tsr)\n",
        "    tensors_res = torch.cat(tensors_padded, dim=0)\n",
        "    return tensors_res\n",
        "\n",
        "\n",
        "def pad_collate_fn(batch: list[dict[str, torch.Tensor]], pad_token_id: int) -> dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Collates and pads a batch of tokenized examples for model input.\n",
        "\n",
        "    This function takes a batch of examples where each example is a dictionary containing\n",
        "    token IDs for the prompt, the chosen response, and the rejected response. For each field,\n",
        "    it extracts the list of token IDs, creates a corresponding attention mask (with ones for each token),\n",
        "    and then pads the sequences using a `pad` function. The prompt sequences and their attention masks\n",
        "    are padded on the left, while the chosen and rejected sequences are padded on the right (default).\n",
        "\n",
        "    Args:\n",
        "        batch (list[dict[str, torch.Tensor]]): A list of dictionaries, where each dictionary has the keys:\n",
        "            - \"prompt_input_ids\": Tensor of token IDs for the prompt.\n",
        "            - \"chosen_input_ids\": Tensor of token IDs for the chosen response.\n",
        "            - \"rejected_input_ids\": Tensor of token IDs for the rejected response.\n",
        "        pad_token_id (int): Padding value for token IDs.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, torch.Tensor]: A dictionary containing the following keys with padded tensors:\n",
        "            - \"prompt_input_ids\": Padded token IDs for the prompt (padded on the left).\n",
        "            - \"prompt_attn_mask\": Padded attention mask for the prompt (padded on the left, with 1s for actual tokens).\n",
        "            - \"chosen_input_ids\": Padded token IDs for the chosen response.\n",
        "            - \"chosen_attn_mask\": Padded attention mask for the chosen response.\n",
        "            - \"rejected_input_ids\": Padded token IDs for the rejected response.\n",
        "            - \"rejected_attn_mask\": Padded attention mask for the rejected response.\n",
        "    \"\"\"\n",
        "    # todo()\n",
        "    prompt_mode = 'left'\n",
        "    chosen_mode = 'right'\n",
        "    rejected_mode = 'right'\n",
        "\n",
        "    prompt_ids = [\n",
        "        batch[idx]['prompt_input_ids']\n",
        "        for idx in range(len(batch))\n",
        "    ]\n",
        "\n",
        "    chosen_ids = [\n",
        "        batch[idx]['chosen_input_ids']\n",
        "        for idx in range(len(batch))\n",
        "    ]\n",
        "\n",
        "    rejected_ids = [\n",
        "        batch[idx]['rejected_input_ids']\n",
        "        for idx in range(len(batch))\n",
        "    ]\n",
        "\n",
        "    prompt_attn = [torch.full_like(prompt_ids[idx], 1) for idx in range(len(prompt_ids))]\n",
        "    chosen_attn = [torch.full_like(chosen_ids[idx], 1) for idx in range(len(chosen_ids))]\n",
        "    rejected_attn = [torch.full_like(rejected_ids[idx], 1) for idx in range(len(rejected_ids))]\n",
        "\n",
        "    result = {\n",
        "        'prompt_input_ids': pad(prompt_ids, pad_token_id, prompt_mode),\n",
        "        'prompt_attn_mask': pad(prompt_attn, 0, prompt_mode),\n",
        "        'chosen_input_ids': pad(chosen_ids, pad_token_id, chosen_mode),\n",
        "        'chosen_attn_mask': pad(chosen_attn, 0, chosen_mode),\n",
        "        'rejected_input_ids': pad(rejected_ids, pad_token_id, rejected_mode),\n",
        "        'rejected_attn_mask': pad(rejected_attn, 0, rejected_mode),\n",
        "    }\n",
        "    return result\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset.with_format(\"torch\"),\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    collate_fn=partial(pad_collate_fn, pad_token_id=tokenizer.pad_token_id),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "749c4e48-9566-4314-9145-799465036404",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T20:57:53.634806Z",
          "iopub.status.busy": "2025-03-28T20:57:53.634399Z",
          "iopub.status.idle": "2025-03-28T20:57:53.726342Z",
          "shell.execute_reply": "2025-03-28T20:57:53.725397Z",
          "shell.execute_reply.started": "2025-03-28T20:57:53.634777Z"
        },
        "id": "749c4e48-9566-4314-9145-799465036404",
        "outputId": "f412b8ee-3c13-4203-a632-63464736653a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt_input_ids': tensor([[    2,     2,     2,     2,     2,     2,     2,     1,  4093,   198,\n",
              "           1780,   506,   260,   768,  3684,  1863,   355,  7704,   346,  3543,\n",
              "           1012,    31, 14608,  3928,    47,     2,   198,     1,   520,  9531,\n",
              "            198],\n",
              "         [    1,  4093,   198,  1780,   506,   260,  1450,  5042,   346,  3543,\n",
              "           2042,  3656,    47,  6244,  4502,   357,   288,   346,   284,  1701,\n",
              "            436,   357,   588, 31702,    47,     2,   198,     1,   520,  9531,\n",
              "            198]]),\n",
              " 'prompt_attn_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1]]),\n",
              " 'chosen_input_ids': tensor([[ 2683,   699,    28,   339,  5248,   253,  2066, 10136,   282,  1101,\n",
              "             29, 16775,    28,   588,   339,  3928, 12635,   476, 40909,  2264,\n",
              "             18,   365, 13671,   346,  2269,   357, 14199,   284,   357, 10878,\n",
              "          32117,   957,  1945,    17,   378,   970,   502,  4944,   351,   655,\n",
              "            284,  1789,   436,   588,  2275,    29, 32031,    30,   339,  5732,\n",
              "            638,   357,  1135,   549,  1962,   260,  2177,   282,  4174,    30,\n",
              "           5310,   346,  2269,   750,  1123,  1101,    29, 16775, 10026,   355,\n",
              "           2744, 24382,    47,   198,   198,  3528,   347,   327,  2905,    28,\n",
              "            339,  3543,   719,  2455,   288,   820,  1056,   618,  2539,    28,\n",
              "            564,   339,  3543,   719,   588, 10229, 36498,   351, 11772,   702,\n",
              "            346, 40303,   228,    30,  1812,   563,   346,    28,   457,   346,\n",
              "           1012,  3534,  6412,  3928,    47,  7948,   634,  7400,   736,   820,\n",
              "            549,  1056,   618,  2539,  1163,    17, 15107,   237,   244,     2,\n",
              "            198,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2],\n",
              "         [ 7764,    28,   338,   506,   253,  1109,  1962,    17,   339,  3543,\n",
              "           3656,   253,  2341,   282, 16626,  5042,   690,   260,   929,    28,\n",
              "            564,   582,  3800,   338,  2159,  6443,   578,  2422,   429,   957,\n",
              "           5295,  2432,    30,   198,   198,  8113,  3783,   549,    28,   476,\n",
              "           8084,   982,  1188,  2747,  1147,  9939,    30,  5330,   506,  1147,\n",
              "           1890,   288,   325,   588,  1759,   335,  2747,  1270,   657,   436,\n",
              "            981,   253,   655,   645,   339,   436,  2159, 10032,   351, 18423,\n",
              "            918,   284,  4693,    30,   339,   436,  7192,   970,  1147,  1083,\n",
              "           2456,   335,  7576,   288,  6888,    28,   284,   357,   436,  2498,\n",
              "            253, 15219,   335,   957,  2898,   864,    30,   198,   198,  1780,\n",
              "           1135,   451,  5042,   588, 31702,   436,   338,   357,  2422,   429,\n",
              "           2206,   617,   761,   719,   738,   588,  1083,   281,   874,  1029,\n",
              "             30,  3361,  5295,  2432,  6679,   614,   981,   253,  1913,    28,\n",
              "           3590,  5732,  2911,    28,   284,  5263,   874,  2419,   282,  9409,\n",
              "             30,  6754,    28,  1041,   436,   582,   282,   260,   768,  2731,\n",
              "            284,  1176,  5725,   701,   339,  3543,  2042,  1278,    30,   198,\n",
              "            198,  2427,  1041,  1137,   967,  1924,    28,   357,   436,   702,\n",
              "            253,  2613, 21051,   767,   957, 15473,    30,   339,  6638,   338,\n",
              "            339,  3683,   982,   457,   288,   325,  3468,    28,   338,   357,\n",
              "            506, 14867,   288,   919,  9101,    28,   284,   338,  1029,   314,\n",
              "           4972,   288,   325,  9765,    28,   441,   915, 11663,    30,   198,\n",
              "            198,  1589,   597,  1135,   549,  7319,   338,  2573,   553,   480,\n",
              "           1038,  9409,    28,   787,  2631,   638,  1830,    29, 35935,   502,\n",
              "            654,  2395,    30,  3361,  5295,  2432,   506,  5042,  5309,   549,\n",
              "            288,   325, 46426,   288,  7576,   284,  1449,    28,   284,   288,\n",
              "            441,  1188,  1495,  1147,  9939,    30,   198,   198,  2068,   451,\n",
              "           1194,    28,   339,  5007,  7576,   282,   967,  1924,  7562,   339,\n",
              "           1120,   288,  1407, 16026,   355,  2609,   282,  7576,    30,   657,\n",
              "            506,   253,  1109, 13151,   288,  1188,   253,  1833,  1056,    28,\n",
              "          12720,    28,   284,  1593,   335,   732,  2159,  5939,    30,     2,\n",
              "            198]]),\n",
              " 'chosen_attn_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
              " 'rejected_input_ids': tensor([[   57,  5248, 11830,   339,  1326,   982,   457,  2143,  2647,   355,\n",
              "          18266,  2123,    28,   715,   347,  2539,   355,  7956, 10026,    28,\n",
              "            347,   339,   744,   253,  1578,  2724,  9127,   288,  1538, 17628,\n",
              "            284, 32707,  5928,    30,  3361,  3446,   314,   288, 28850,  5161,\n",
              "            284,  7002,  1096,   288,   260,  1450,   282,   957,  1967,   284,\n",
              "           6236,    28,  2161,   670,  4798,   281, 15390,  2123,    30,   198,\n",
              "            198,  4460,    28,   339,   416,  1538,   346,   351,  1096,   335,\n",
              "           1461,  2905,   355, 10026,   338,   457,  3656,  2609, 43494,   355,\n",
              "            359,  4006,   288,  1678,  4366,    28,   868,   346,   325,  4854,\n",
              "             30,  8765,  1407,  1904,   288,  9571,   253,  1678, 13926,    28,\n",
              "            284,   339,   523,   536,   957,  1450,   288,  1538,   253,  5356,\n",
              "            284, 17628,  2426,    30,     2,   198,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2],\n",
              "         [14229,  1194,    30,   339,  5248,   354,  6416,  5290,  1789,  1743,\n",
              "             28,   284,   347,   715,    28,   339,  1326,   982,   457,  2143,\n",
              "           2647,   355,  3796,  5042,   429,  2048,    30,  1423,    28,   339,\n",
              "            416,  1538,   253,  2426,   338,   314,  1062, 17628,   284,  4006,\n",
              "            288,   260,  4234,   418,  1369,    30,   198,   198,  2705,   282,\n",
              "            260,   768,  3172,  4443,   282,  5042,   338,   339,   416,  2626,\n",
              "            314,   260,  2979,   282,  2437,   284,  2430,  2908,    30,   657,\n",
              "            314,  3202,   288,  7218,  1096,   281,   253, 19484,    28,  5161,\n",
              "             28,   284, 16503,  5710,    28,  9312, 23325,   284,  4659,   338,\n",
              "            260,  5492,  3714,   314,  8753,  6026,    30,   198,   198,  1348,\n",
              "           5042,   314, 31702,   975,  2430,  2908,   314,   260, 24604,   282,\n",
              "           3424,  5759,    28,  1991,  2143,   355,  3544,    30,  1428, 13794,\n",
              "           4763,   284, 29569,    28,  2048,   416,  1235,  3634,    28,  6366,\n",
              "           5339,    28,   284,  3025,   480,  3949,   351,  2852,  8801,    30,\n",
              "            198,   198,  3965,   339,  3683,   982,  3796,   451,  5042,   429,\n",
              "            253,  1678,  1212,    28,   357,   314,  1552,   335,   260,  3618,\n",
              "            282,  2430,  2908,   338,   359,  4889, 14494,   284, 16003,    30,\n",
              "           1032,   253,  3544,  1789,  1743,    28,   339, 11635,   288, 18398,\n",
              "            623,  3618,   281,   957,  5759,    28,  3258,  5161,   284, 17628,\n",
              "           5928,   338,  7304,  3424,  2908,    30,   198,   198,   788,  4446,\n",
              "             28,   260,  2979,   282,  2437,   284,  2430,  2908,  2526,   325,\n",
              "            690, 31916,    30,  1428, 38013,   451,  2325,   282,  6019,    28,\n",
              "           2048,   416, 27144,  3824,  2624,    28,  1062, 11461,   284, 24603,\n",
              "             30,     2,   198]]),\n",
              " 'rejected_attn_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(dataloader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628ab5cb-dd61-4f97-bd11-e790470119bf",
      "metadata": {
        "id": "628ab5cb-dd61-4f97-bd11-e790470119bf"
      },
      "source": [
        "## DPO Loss [5 –±–∞–ª–ª–æ–≤]\n",
        "\n",
        "–ù–∞—á–Ω–µ–º —Å –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–∞–º–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å. –û–Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å—Ç–∞—è, —Å–ª–µ–¥—É–π—Ç–µ —Ñ–æ—Ä–º—É–ª–µ –¥–æ—Å–ª–æ–≤–Ω–æ –∏ –≤—Å–µ –ø–æ–ª—É—á–∏—Ç—Å—è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8954ebd-0de5-4130-8a56-a2135191a7aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-15T18:37:44.079094Z",
          "iopub.status.busy": "2025-03-15T18:37:44.078889Z",
          "iopub.status.idle": "2025-03-15T18:37:44.082243Z",
          "shell.execute_reply": "2025-03-15T18:37:44.081416Z",
          "shell.execute_reply.started": "2025-03-15T18:37:44.079076Z"
        },
        "id": "a8954ebd-0de5-4130-8a56-a2135191a7aa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# torch.tensor([True, False]).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "183621d5-0d24-446b-856b-037d4075231c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T20:55:15.701596Z",
          "iopub.status.busy": "2025-03-28T20:55:15.701251Z",
          "iopub.status.idle": "2025-03-28T20:55:15.708511Z",
          "shell.execute_reply": "2025-03-28T20:55:15.707298Z",
          "shell.execute_reply.started": "2025-03-28T20:55:15.701570Z"
        },
        "id": "183621d5-0d24-446b-856b-037d4075231c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def dpo_loss(\n",
        "    chosen_logps: torch.Tensor,\n",
        "    rejected_logps: torch.Tensor,\n",
        "    ref_chosen_logps: torch.Tensor,\n",
        "    ref_rejected_logps: torch.Tensor,\n",
        "    beta: float = 0.1,\n",
        ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Computes the Direct Preference Optimization (DPO) loss and associated reward metrics.\n",
        "\n",
        "    Args:\n",
        "        chosen_logps (Tensor): A tensor of shape (batch_size,) containing the log-probabilities of the chosen responses.\n",
        "        rejected_logps (Tensor): A tensor of shape (batch_size,) containing the log-probabilities of the rejected responses.\n",
        "        ref_chosen_logps (Tensor): A tensor of shape (batch_size,) containing the reference log-probabilities for chosen responses.\n",
        "        ref_rejected_logps (Tensor): A tensor of shape (batch_size,) containing the reference log-probabilities for rejected responses.\n",
        "        beta (float, optional): A scaling factor applied to the differences in log-probabilities. Defaults to 0.1.\n",
        "\n",
        "    Returns:\n",
        "        tuple[Tensor, Tensor, Tensor]:\n",
        "            - loss (Tensor): The computed DPO loss as a scalar tensor.\n",
        "            - reward_accuracies (Tensor): The fraction of examples where the chosen reward exceeds the rejected reward.\n",
        "            - reward_margins (Tensor): The average difference between the chosen and rejected rewards.\n",
        "    \"\"\"\n",
        "    # todo()\n",
        "    log_chosen_ratio = chosen_logps - ref_chosen_logps\n",
        "    log_rejected_ratio = rejected_logps - ref_rejected_logps\n",
        "    log_prob = F.logsigmoid(beta * log_chosen_ratio - beta * log_rejected_ratio)\n",
        "    dpo_loss_val = -1 * torch.mean(log_prob)\n",
        "\n",
        "    chosen_more_rejected = torch.mean((log_chosen_ratio > log_rejected_ratio).float())\n",
        "\n",
        "    avg_margin = torch.mean(log_chosen_ratio - log_rejected_ratio)\n",
        "\n",
        "    return dpo_loss_val, chosen_more_rejected, avg_margin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "a3093e12-bdf4-4777-9581-cc38e9c2362b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-15T18:37:44.095903Z",
          "iopub.status.busy": "2025-03-15T18:37:44.095612Z",
          "iopub.status.idle": "2025-03-15T18:37:44.108423Z",
          "shell.execute_reply": "2025-03-15T18:37:44.107777Z",
          "shell.execute_reply.started": "2025-03-15T18:37:44.095875Z"
        },
        "id": "a3093e12-bdf4-4777-9581-cc38e9c2362b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# a = torch.randn(2, 2, 12)\n",
        "# b = torch.tensor([[0, 5], [1, 3]])\n",
        "# torch.sum(F.softmax(a, dim=-1)[0, 0, :])\n",
        "# torch.gather(F.softmax(a, dim=-1), -1, b.unsqueeze(-1)).squeeze(),\n",
        "# F.softmax(a, dim=-1)[0, 0, 0], F.softmax(a, dim=-1)[0, 1, 5],\n",
        "# F.softmax(a, dim=-1)[1, 0, 1], F.softmax(a, dim=-1)[1, 1, 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8351081-cb90-4a02-9796-59db45944dce",
      "metadata": {
        "id": "f8351081-cb90-4a02-9796-59db45944dce"
      },
      "source": [
        "–î–ª—è —É–¥–æ–±—Å—Ç–∞ —Ç–∞–∫–∂–µ –æ–ø—Ä–µ–¥–µ–ª–∏–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —á—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å –ª–æ–≥-–ø—Ä–æ–±—ã –ø–æ –ª–æ–≥–∏—Ç–∞–º. –í–∞–º –Ω—É–∂–Ω–æ –≤—ã—Ç–∞—â–∏—Ç—å –ª–æ–≥–∏—Ç—ã —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥-–ø—Ä–æ–±—ã –ø—Ä–æ–º–ø—Ç–∞ –ø–µ—Ä–µ–¥ –∞–≥–≥—Ä–µ–≥–∞—Ü–∏–µ–π. –ú–∞—Å–∫–∞ –∑–¥–µ—Å—å —É–∂–µ –¥–∞–Ω–∞.\n",
        "\n",
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥—É–º–∞–π—Ç–µ –∫–∞–∫ —Å–æ–æ—Ç–Ω–æ—Å—è—Ç—Å—è –ª–æ–≥–ø—Ä–æ–±—ã –∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã, –∏–Ω–∞—á–µ —Ä–∏—Å–∫—É–µ—Ç–µ –æ—à–∏–±–∏—Ç—å—Å—è –Ω–∞ 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "c81deee5-e71c-4709-b766-ffcb7ab365c8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T20:55:25.624399Z",
          "iopub.status.busy": "2025-03-28T20:55:25.624014Z",
          "iopub.status.idle": "2025-03-28T20:55:25.630455Z",
          "shell.execute_reply": "2025-03-28T20:55:25.629426Z",
          "shell.execute_reply.started": "2025-03-28T20:55:25.624366Z"
        },
        "id": "c81deee5-e71c-4709-b766-ffcb7ab365c8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_log_prob(logits: torch.Tensor, labels: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the log probability for each sequence in a batch.\n",
        "\n",
        "    Args:\n",
        "        logits (Tensor): A tensor of shape [batch_size, seq_len, vocab_size]\n",
        "            representing the model's output logits.\n",
        "        labels (Tensor): A tensor of shape [batch_size, seq_len] containing the target token indices.\n",
        "        mask (Tensor): A tensor of shape [batch_size, seq_len] indicating which tokens to include\n",
        "            in the log probability (e.g., 1 for valid tokens and 0 for padding or prompt).\n",
        "\n",
        "    Returns:\n",
        "        Tensor: A tensor of shape [batch_size,] containing the log probability for each sequence.\n",
        "    \"\"\"\n",
        "    # todo()\n",
        "    labels = labels[:, 1:]\n",
        "    logits = logits[:, :-1, :]\n",
        "    mask = mask[:, 1:]\n",
        "    probs = F.log_softmax(logits, dim=-1)\n",
        "    probs = torch.gather(probs, -1, labels.unsqueeze(-1)).squeeze()\n",
        "    probs = torch.sum(probs * mask, dim=-1)\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d528b248-2040-4605-b20a-6e43269a531c",
      "metadata": {
        "id": "d528b248-2040-4605-b20a-6e43269a531c"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ DPO [5 –±–∞–ª–ª–æ–≤]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597a061a-def0-4dfe-ac5a-309044b08a79",
      "metadata": {
        "id": "597a061a-def0-4dfe-ac5a-309044b08a79"
      },
      "source": [
        "–ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –¥–∞—Ç–∞—Å–µ—Ç —Å –Ω—É–ª—è.\n",
        "–î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –æ–≥—Ä–∞–Ω–∏—á–∏–º—Å—è –æ–±—ã—á–Ω—ã–º —Ü–∏–∫–ª–æ–º, –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥–æ–≤, –∫–ª–∞—Å—Å–æ–≤ –∏ –ø—Ä–æ—á–µ–≥–æ.\n",
        "–í—ã –º–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –∫–∞–∫ —É–¥–æ–±–Ω–æ –≤–∞–º, –≥–ª–∞–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å.\n",
        "\n",
        "–í—Å–µ –Ω—É–∂–Ω–æ–µ —É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å, –æ—Å—Ç–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —ç—Ç–æ –≤—Å–µ –≤–º–µ—Å—Ç–µ.\n",
        "–î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ª–æ–≥–ø—Ä–æ–±—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç+–≤—ã–±—Ä–∞–Ω–Ω—ã–π –∏ –ø—Ä–æ–º–ø—Ç+–æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç—ã.\n",
        "–ù–µ –∑–∞–±—ã—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ–±—Ä–∞—Ç—å –º–∞—Å–∫—É –¥–ª—è –ª–æ—Å—Å–∞.\n",
        "–í –∫–æ–Ω—Ü–µ –æ–±—Ä–µ–∑–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≤—Ö–æ–¥—ã –¥–ª—è –º–æ–¥–µ–ª–∏ –¥–æ `MAX_SEQ_LEN` (—Å –Ω—É–∂–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã!).\n",
        "\n",
        "–û–±—É—á–µ–Ω–∏–µ –∑–∞–Ω–∏–º–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ —á–∞—Å –Ω–∞ Colab T4 GPU, 2 –º–∏–Ω—É—Ç –Ω–∞ H100. –í Colab –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å float16 –∏ AMP.\n",
        "–ù–µ –∑–∞–±—É–¥—å—Ç–µ –ø—Ä–æ —Å–∫–µ–π–ª–∏–Ω–≥. –î–ª—è bf16 –æ–Ω –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω.\n",
        "\n",
        "**NB**: –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Kaggle Notebooks, —Ç.–∫. –æ–Ω–∏ –Ω–µ –≤—ã–ª–µ—Ç–∞—é—Ç –µ—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å —Ç–µ—Ç—Ä–∞–¥–∫–æ–π. –ò—Ö –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–ª—è—Ç—å –Ω–∞ —á–∞—Å –±–µ–∑ –±–æ—è–∑–Ω–∏, —á—Ç–æ –æ–Ω–∏ —É–ø–∞–¥—É—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2290d52a-a5c3-4dab-a448-94a9cddd4e46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T21:33:22.202608Z",
          "iopub.status.busy": "2025-03-28T21:33:22.202296Z",
          "iopub.status.idle": "2025-03-28T21:33:22.279168Z",
          "shell.execute_reply": "2025-03-28T21:33:22.278397Z",
          "shell.execute_reply.started": "2025-03-28T21:33:22.202586Z"
        },
        "id": "2290d52a-a5c3-4dab-a448-94a9cddd4e46",
        "outputId": "c600933d-9d4f-4761-ec10-1dd4c2d8cc45",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 'cpu' device\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 2  # in colab make it smaller, or implement grad accumulation\n",
        "NUM_EPOCHS = 1\n",
        "LR = 5e-5\n",
        "MAX_SEQ_LEN = 1024  # this also can be adjusted\n",
        "MAX_PROMPT_LEN = 256 # this also can be adjusted\n",
        "MAX_COMPLETION_LEN = None\n",
        "BETA = 1.0\n",
        "# BETA = 0.1\n",
        "\n",
        "# –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –≤–∞–º —Ö–æ—á–µ—Ç—Å—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ W&B\n",
        "ENABLE_WANDB = False\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "print(f\"Using '{DEVICE}' device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2d965a85-ae7b-4b88-9c62-aaebe54c4b2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "0596c4d9027d4f2aa0f14d70897ad910",
            "63ce064f8e6a46c69856b653666a9aeb",
            "4fd37ec07a1f4d72bdbe63086986b3bc",
            "2c4a5bb04b414658a2085d7f56e23865",
            "59fbd435254a425c8a792dc909caa6e8",
            "e272d30b3d4942a786fa20eb48b4ecd7",
            "9af977c16e9847078b66c471b161c5ab",
            "2e7b1e44afaa4da5be8643b50b7986fe",
            "952d00751b7d4f4a92a63cc16b1d3f91",
            "f9d4265b3704442eab0cbced7e25d259",
            "ab4cbbc7b77947009245733852b40a07",
            "204e99217541433dafd010ffc1fca2a1",
            "6751043e2d6f48baa3a402b7c5ffb596",
            "89b9c031423c4cce9ccdf49649882b99",
            "3cca63a666244c83b2db19acaa44c237",
            "90c8b4a0792e45d7ba586a6ad90e916b",
            "37d07433786e41f5afba715893035f86",
            "cf265f9ed1f546a291e853de114d2ea1",
            "5632118a3b7941e0a7bd10a49174442f",
            "8c9114abb4e64222832f6143663ea785",
            "bba52c87ce3945a9b54d15ea562cab2c",
            "834884ef14c64709aa4d77e1e351624f",
            "52dc77a77b0949a0b72b125d55fde10d",
            "114db4aa577f4d23b2c30847006340db",
            "3619eb7631c54c2faec9eda3fe808777",
            "2738269baa104c0886d922932f3dc90f",
            "a3512a7c182c429aab4ad6c24024412b",
            "aaf3d8a949884c649130fc3220be6748",
            "8b9482c396a8479f9ec094816c3cabe9",
            "d6bbe0d878c84fb4a2e7f2bf569b0b4b",
            "491030b3b886455a90cdb3158c6722f6",
            "21d50ddc66974db5b1edf22067069f7a",
            "b0ffc310a2a64d428612aa833e985734"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T21:01:17.974267Z",
          "iopub.status.busy": "2025-03-28T21:01:17.973914Z",
          "iopub.status.idle": "2025-03-28T21:01:24.470558Z",
          "shell.execute_reply": "2025-03-28T21:01:24.469613Z",
          "shell.execute_reply.started": "2025-03-28T21:01:17.974241Z"
        },
        "id": "2d965a85-ae7b-4b88-9c62-aaebe54c4b2c",
        "outputId": "1f27b3f2-2f76-4f8d-a790-3ccbd88e2193",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0596c4d9027d4f2aa0f14d70897ad910",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "204e99217541433dafd010ffc1fca2a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52dc77a77b0949a0b72b125d55fde10d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "set_seed(42)\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    wandb.init(project=\"hw2-rlhf\", group=\"dpo\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    # only if you have A/H100 GPU\n",
        "    # torch_dtype=torch.bfloat16,\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "model.train()\n",
        "disable_dropout_in_model(model)\n",
        "\n",
        "ref_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    # only if you have A/H100 GPU\n",
        "    # torch_dtype=torch.bfloat16,\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "ref_model.eval()\n",
        "disable_dropout_in_model(ref_model)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer})\n",
        "dataset = dataset.map(\n",
        "    tokenize_row,\n",
        "    fn_kwargs={\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"max_prompt_length\": MAX_PROMPT_LEN,\n",
        "        \"max_completion_length\": MAX_COMPLETION_LEN,\n",
        "    },\n",
        "    remove_columns=[\"prompt\", \"chosen\", \"rejected\"],\n",
        "    # load_from_cache_file=False,\n",
        ")\n",
        "dataloader = DataLoader(\n",
        "    dataset.with_format(\"torch\"),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    pin_memory=False,\n",
        "    collate_fn=partial(pad_collate_fn, pad_token_id=tokenizer.pad_token_id),\n",
        ")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    losses, accs, margins = [], [], []\n",
        "\n",
        "    pbar = tqdm(dataloader, desc=\"Epoch\", leave=False)\n",
        "    for batch in pbar:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        # 1. Concatenate the prompt and completion inputs for chosen & rejected\n",
        "        fin_cut = lambda x: x[:, :MAX_SEQ_LEN]\n",
        "\n",
        "        chosen_prompt_ids = torch.hstack((batch['prompt_input_ids'], batch['chosen_input_ids']))\n",
        "        chosen_prompt_attn = torch.hstack((batch['prompt_attn_mask'], batch['chosen_attn_mask']))\n",
        "        chosen_prompt_ids, chosen_prompt_attn = fin_cut(chosen_prompt_ids), fin_cut(chosen_prompt_attn)\n",
        "        chosen_sz = chosen_prompt_ids.shape[1] - batch['prompt_input_ids'].shape[1]\n",
        "\n",
        "        rejected_prompt_ids = torch.hstack((batch['prompt_input_ids'], batch['rejected_input_ids']))\n",
        "        rejected_prompt_attn = torch.hstack((batch['prompt_attn_mask'], batch['rejected_attn_mask']))\n",
        "        rejected_prompt_ids, rejected_prompt_attn = fin_cut(rejected_prompt_ids), fin_cut(rejected_prompt_attn)\n",
        "        rejected_sz = rejected_prompt_ids.shape[1] - batch['prompt_input_ids'].shape[1]\n",
        "\n",
        "        # 2. Calculate logits for current and reference models for chosen and rejected samples\n",
        "        chosen_logits = model(chosen_prompt_ids, attention_mask=chosen_prompt_attn)['logits']\n",
        "        rejected_logits = model(rejected_prompt_ids, attention_mask=rejected_prompt_attn)['logits']\n",
        "        with torch.no_grad():\n",
        "            chosen_logits_ref = ref_model(chosen_prompt_ids, attention_mask=chosen_prompt_attn)['logits']\n",
        "            rejected_logits_ref = ref_model(rejected_prompt_ids, attention_mask=rejected_prompt_attn)['logits']\n",
        "\n",
        "        # 3. Calculate log probs for all models (no concat as in TRL for simplicity and to save memory with smaller batch size\n",
        "        chosen_lgs, chosen_lgs_ref = chosen_logits[:, -chosen_sz:, :], chosen_logits_ref[:, -chosen_sz:, :]\n",
        "        rejected_lgs, rejected_lgs_ref = rejected_logits[:, -rejected_sz:, :], rejected_logits_ref[:, -rejected_sz:, :]\n",
        "        chosen_labels, chosen_attn = chosen_prompt_ids[:, -chosen_sz:], chosen_prompt_attn[:, -chosen_sz:]\n",
        "        rejected_labels, rejected_attn = rejected_prompt_ids[:, -rejected_sz:], rejected_prompt_attn[:, -rejected_sz:]\n",
        "        chosen_logps = get_log_prob(chosen_lgs, chosen_labels, chosen_attn)\n",
        "        chosen_logps_ref = get_log_prob(chosen_lgs_ref, chosen_labels, chosen_attn)\n",
        "        rejected_logps = get_log_prob(rejected_lgs, rejected_labels, rejected_attn)\n",
        "        rejected_logps_ref = get_log_prob(rejected_lgs_ref, rejected_labels, rejected_attn)\n",
        "\n",
        "        # 4. Calculate loss\n",
        "        loss, reward_accuracies, reward_margins = dpo_loss(\n",
        "            chosen_logps,\n",
        "            rejected_logps,\n",
        "            chosen_logps_ref,\n",
        "            rejected_logps_ref,\n",
        "            beta=BETA,\n",
        "        )\n",
        "        if torch.isnan(loss):\n",
        "            raise RuntimeError(\"Loss is NaN!\")\n",
        "\n",
        "        # 5. Make optimizer step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # if (i // batch_size + 1) % accumulation_steps == 0:\n",
        "        #     optimizer.step()\n",
        "        #     optimizer.zero_grad()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        accs.append(reward_accuracies.item())\n",
        "        margins.append(reward_margins.item())\n",
        "        pbar.set_postfix({\n",
        "            \"Reward margin\": reward_margins.item(),\n",
        "            \"Reward acc\": reward_accuracies.item(),\n",
        "            \"dpo_loss\": loss.item(),\n",
        "            # \"Reward margins avg\": np.mean(margins),\n",
        "            # \"Reward acc avg\": np.mean(accs),\n",
        "        })\n",
        "\n",
        "    pbar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "_q7zo_SQBH1k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q7zo_SQBH1k",
        "outputId": "c09b1f16-40d9-4745-fdbb-30b0dc802127"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model.load_state_dict(\n",
        "#     torch.load(\"/content/drive/MyDrive/dpo_weights_right_5.pth\", weights_only=True, map_location=DEVICE)\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef3e6ab0-9437-473e-abcd-0dd33c974570",
      "metadata": {
        "id": "ef3e6ab0-9437-473e-abcd-0dd33c974570"
      },
      "source": [
        "–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è reward margins –∏ accuracy –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏ —Ä–∞—Å—Ç–∏. –î–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "kPRcqqaaCqmY",
      "metadata": {
        "id": "kPRcqqaaCqmY"
      },
      "outputs": [],
      "source": [
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     f\"{REPO_NAME}-dpo\",\n",
        "#     attn_implementation=\"sdpa\",\n",
        "#     device_map=DEVICE,\n",
        "# )\n",
        "# model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "8b739545-0c57-4ede-a874-788236b38420",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "execution": {
          "iopub.execute_input": "2025-03-28T21:08:59.672318Z",
          "iopub.status.busy": "2025-03-28T21:08:59.671886Z",
          "iopub.status.idle": "2025-03-28T21:09:22.776953Z",
          "shell.execute_reply": "2025-03-28T21:09:22.775798Z",
          "shell.execute_reply.started": "2025-03-28T21:08:59.672284Z"
        },
        "id": "8b739545-0c57-4ede-a874-788236b38420",
        "outputId": "92b766e2-1377-44f0-8e71-865607decdae",
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======== BEFORE TUNING ========\n",
            "user\n",
            "What's your morning routine like?\n",
            "assistant\n",
            "Morning routine! My 6-year-old has a daily routine that's tailored to his personality, interests, and well-being. Here's my daily routine for Monday:\n",
            "\n",
            "**Pre-Morning Routine (4-5 minutes)**\n",
            "\n",
            "1. **Get dressed**: My 6-month-old's diaper needs to be dirty and fresh, so I gently wipe them down with a toy or cloth, and let's add the combs to the front.\n",
            "2. **Brush his teeth**: We start with an apple or a straw and put the toothpaste in a small ball and let's brush him teeth.\n",
            "3. **Get ready to go**: I gently rub my infant's arms and legs after a meal and before bed to remove any remaining saliva.\n",
            "\n",
            "**Morning Routine (10-15 minutes)**\n",
            "\n",
            "1. **Clean the diaper**: I pour water and let's add a small amount of soap. He'll roll into a puddle, and I gently pour a small amount of baby shampoo into it.\n",
            "2. **Touch his face**: I gently touch his face, back, and neck, focusing on the eyes and hands. Make eye contact, so my baby feels like he's in a hug\n",
            "\n",
            "======== AFTER TUNING ========\n",
            "user\n",
            "What's your morning routine like?\n",
            "assistant\n",
            "So, I'm a morning pick-me-up. I love the fresh start, the wake-up light, and the promise of a good start of the day. I love the feeling of the sun rising over the horizon, a quiet morning start to the day, but also a start to the day that's got me feeling refreshed and renewed.\n",
            "\n",
            "In my first month, I was a bit hesitant to start using the morning routine, but the idea of taking a few minutes to prep and pack out was starting to resonate with me. I felt a bit lost, but also a bit excited, and it was amazing to feel. After a few minutes of putting on some clothes, brushing my teeth, and sipping on a hot cup of coffee, I could make it through the first 30 minutes on this Monday morning. It was a long journey, but I knew I couldn't go through with it overnight.\n",
            "\n",
            "So, I started to do some simple, but effective morning routines that were tailored to my needs. I used warm drinks, took short walks outside (but not too close, as the sun would feel like it was setting a bit far), and even made a small cup of lattes on my morning shower. They worked, and I\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=True)\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "init_generated_ids = ref_model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=True)\n",
        "init_response = tokenizer.batch_decode(init_generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"======== BEFORE TUNING ========\")\n",
        "print(init_response)\n",
        "print()\n",
        "\n",
        "print(\"======== AFTER TUNING ========\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "cbb73140",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T21:04:59.926906Z",
          "iopub.status.busy": "2025-03-28T21:04:59.926439Z",
          "iopub.status.idle": "2025-03-28T21:05:28.062334Z",
          "shell.execute_reply": "2025-03-28T21:05:28.061206Z",
          "shell.execute_reply.started": "2025-03-28T21:04:59.926854Z"
        },
        "id": "cbb73140",
        "outputId": "800bdf35-27ae-4689-c7f5-5b50c1dfe284",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Dayara13/llm-course-hw2-dpo/commit/31d84ec49af9136f278750f63fba5342c7316f2e', commit_message='Upload tokenizer', commit_description='', oid='31d84ec49af9136f278750f63fba5342c7316f2e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Dayara13/llm-course-hw2-dpo', endpoint='https://huggingface.co', repo_type='model', repo_id='Dayara13/llm-course-hw2-dpo'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞ —Ö–∞–±\n",
        "\n",
        "model.push_to_hub(f\"{REPO_NAME}-dpo\")\n",
        "tokenizer.push_to_hub(f\"{REPO_NAME}-dpo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84318ed4-e3db-4151-88fc-cb00755e6b63",
      "metadata": {
        "id": "84318ed4-e3db-4151-88fc-cb00755e6b63"
      },
      "source": [
        "# –ß–∞—Å—Ç—å 2: PPO –∏ TRL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcce2878-10bb-4dd9-9313-137528a0d1b6",
      "metadata": {
        "id": "fcce2878-10bb-4dd9-9313-137528a0d1b6"
      },
      "source": [
        "–í—Ç–æ—Ä–∞—è —á–∞—Å—Ç—å –±—É–¥–µ—Ç —Å–∏–ª—å–Ω–æ –ø—Ä–æ—â–µ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞ —Ç–æ, —á—Ç–æ–±—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å —Å–∞–º–æ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ–π –±–∏–±–ª–æ—Ç–µ–∫–æ–π –¥–ª—è –∞–ª–∞–π–º–µ–Ω—Ç–∞ –æ—Ç huggingface - [TRL](https://huggingface.co/docs/trl/v0.15.0/index). C –ø–æ–º–æ—â—å—é TRL –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –æ–±—É—á–∏—Ç—å PPO, –∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤–Ω–∞—á–∞–ª–µ –æ–±—É—á–∏—Ç—å Reward Model.\n",
        "\n",
        "**–õ–∏—Ä–∏—á–µ—Å–∫–æ–µ –æ—Ç—Å—Ç—É–ø–ª–µ–Ω–∏–µ**: PPO –∏–º–µ–µ—Ç –ø–∞—Ä–∞–¥–æ–∫—Å–∞–ª—å–Ω—É—é —Ä–µ–ø—É—Ç–∞—Ü–∏—é. –° –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–Ω—ã –≤ RL –æ–Ω —Å—á–∏—Ç–∞–µ—Ç—Å—è —á—É—Ç—å –ª–∏ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–∏–º–µ–Ω–∏–º—ã–º (–¥–æ —Å–∏—Ö –ø–æ—Ä) –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–≤–æ–¥–∏—Ç—Å—è —Å –ø–æ–ª-–ø–∏–Ω–∫–∞ –∏ –Ω–∞ –ª—é–±–æ–π –∑–∞–¥–∞—á–µ. –û—Å–Ω–æ–≤–Ω–æ–π –±–æ—Ç—Ç–ª–Ω–µ–∫ –¥–ª—è –Ω–µ–≥–æ - –¥–∞–Ω–Ω—ã–µ, —á–µ–º –±—ã—Å—Ç—Ä–µ–µ —Å–∏–º—É–ª—è—Ç–æ—Ä, —Ç–∞–º –±–æ–ª—å—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, —á—Ç–æ –æ–Ω –≤–∞—à—É –∑–∞–¥–∞—á—É —Ä–µ—à–∏—Ç. –ü—Ä–∏–º–µ—Ä–æ–≤ –º–Ω–æ–≥–æ - —Ç–∞–∫ —Ä–µ—à–∏–ª–∏ Dota 2 –∏–ª–∏ Minecraft. –° –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —É –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∫—Ä–∞–π–Ω–µ –¥—É—Ä–Ω–∞—è —Ä–µ–ø—É—Ç–∞—Ü–∏—è –≤ –ø–ª–∞–Ω–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –Ω—É–ª—è, —Ç.–∫. –µ—Å—Ç—å –º–Ω–æ–≥–æ –≤–∞–∂–Ω—ã—Ö –∏ –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–∏–≤–µ–¥—É—Ç –∫ –Ω–µ–∑–∞–º–µ—Ç–Ω–æ–º—É, –Ω–æ –∫—Ä–∞–π–Ω–µ —Å—Ç—Ä–∞–Ω–Ω–æ–º—É –ø–æ–≤–µ–¥–µ–Ω–∏—é. –î–µ–±–∞–≥–∞—Ç—å —ç—Ç–æ –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ, [—á–µ–≥–æ —Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/) –∏ [—Ç–∞–∫–æ–π –∂–µ –¥–ª—è —É–∂–µ RLHF](https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo), –ø—Ä–∏—á–µ–º —á–∞—Å—Ç–æ —Ç—Ä—é–∫–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –º–µ–∂–¥—É –¥–æ–º–µ–Ω–∞–º–∏. –ë–æ–ª–µ–µ —Ç–æ–≥–æ, –∫–∞–∫ —Ä–∞–∑ –∏–∑-–∑–∞ —ç—Ç–æ–≥–æ –µ—Å–ª–∏ –≤—ã –∑–∞–≥—É–≥–ª–∏—Ç–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ PPO —Å –Ω—É–ª—è, —Å –±–æ–ª—å—à–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –±—É–¥–µ—Ç —Å –æ—à–∏–±–∫–∞–º–∏.\n",
        "\n",
        "–ü–æ—ç—Ç–æ–º—É –∫–æ–¥–∏—Ç—å PPO –±–µ–∑ —Ç–µ—Å–Ω–æ–≥–æ –∑–Ω–∞–∫–æ–º—Å—Ç–≤–∞ –∏ –æ–ø—ã—Ç–∞ –≤ RL –∫—Ä–∞–π–Ω–µ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è. –î–ª—è RLHF –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TRL –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏, –¥–ª—è RL –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [Sample-Factory](https://github.com/alex-petrenko/sample-factory)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1616be4-4106-49a6-8c7f-155081d7263d",
      "metadata": {
        "id": "d1616be4-4106-49a6-8c7f-155081d7263d"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ Reward Model [2 –±–∞–ª–ª]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323184d8-e45a-42a7-aa7a-a59d9ecc50ae",
      "metadata": {
        "id": "323184d8-e45a-42a7-aa7a-a59d9ecc50ae"
      },
      "source": [
        "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç DPO, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–≤–æ–¥–∏—Ç –∞–ø–¥–µ–π—Ç —è–≤–Ω–æ, —É–±–∏—Ä–∞—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ –Ω–∞–≥—Ä–∞–¥–µ, –¥–ª—è PPO –Ω–∞–≥—Ä–∞–¥–∞ –Ω—É–∂–Ω–∞, –∞ –∑–Ω–∞—á–∏—Ç –∫—Ç–æ-—Ç–æ –¥–æ–ª–∂–µ–Ω –µ–µ –≤—ã–¥–∞–≤–∞—Ç—å. –í –æ–±—â–µ–º —Å–ª—É—á–∞–µ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞–∫–∞—è-—Ç–æ –ø—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –Ω–∞–ø—Ä–∏–º–µ—Ä —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º. –î–ª—è PPO, TRL –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞–≥—Ä–∞–¥—ã –æ—Ç –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–∫ (–Ω–æ —ç—Ç–æ –ø–æ–ø—Ä–∞–≤—è—Ç –≤ –±—É–¥—É—â–µ–º).\n",
        "\n",
        "–í–æ–∑—å–º–µ–º —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç –∏ –ø–æ–ø—Ä–æ–±—É–µ–º –æ–±—É—á–∏—Ç—å —Å–∞–º–∏. –î–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è preference dataset with implicit prompt ([—Å–º. –ø—Ä–∏–º–µ—Ä—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏](https://huggingface.co/docs/trl/main/dataset_formats)). –¢–æ –µ—Å—Ç—å –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏: chosen, rejected, –∫–∞–∂–¥–∞—è —Å–æ–¥–µ—Ä–∂–∞—è—â–∞—è –≤ —Å–µ–±–µ –ø—Ä–æ–º–ø—Ç. –ü–æ –∞–Ω–∞–ª–æ–≥–∏–∏, —ç—Ç–æ –≤—Å–µ –Ω–∞–¥–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –≤ —Ç–µ–º–ø–ª–µ–π—Ç —á–∞—Ç–∞.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä:\n",
        "```python\n",
        "## Implicit prompt\n",
        "preference_example = {\n",
        "    \"chosen\": [\n",
        "        {\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"It is blue.\"}\n",
        "    ],\n",
        "    \"rejected\": [\n",
        "        {\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"It is green.\"}\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "–ü–æ–¥—Ä–æ–±–Ω–µ–µ –ø—Ä–æ –ª–æ—Å—Å –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è [—Ç—É—Ç](https://rlhfbook.com/c/07-reward-models.html). TRL –≤—Å–µ —Å–¥–µ–ª–∞–µ—Ç –∑–∞ –≤–∞—Å."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "e1337a76-ab6e-47f6-8d14-3430234b9858",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T21:33:02.221894Z",
          "iopub.status.busy": "2025-03-28T21:33:02.221583Z",
          "iopub.status.idle": "2025-03-28T21:33:02.226722Z",
          "shell.execute_reply": "2025-03-28T21:33:02.225888Z",
          "shell.execute_reply.started": "2025-03-28T21:33:02.221872Z"
        },
        "id": "e1337a76-ab6e-47f6-8d14-3430234b9858",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def to_implicit_prompt_preferences(example: dict[str, str]) -> dict[str, list[dict[str, str]]]:\n",
        "    \"\"\"\n",
        "    Converts an example into implicit prompt preferences format.\n",
        "\n",
        "    Args:\n",
        "        example (dict[str, str]): A dictionary with the following keys:\n",
        "            - \"prompt\": The user's input prompt.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, list[dict[str, str]]]: A dictionary containing:\n",
        "            - \"chosen\": A list of messages forming the conversation for the chosen response.\n",
        "            - \"rejected\": A list of messages forming the conversation for the rejected response.\n",
        "    \"\"\"\n",
        "    # todo()\n",
        "    result = {\n",
        "        'chosen': [\n",
        "            {'role': 'user', 'content': example['prompt']},\n",
        "            {'role': 'assistant', 'content': example['chosen']},\n",
        "        ],\n",
        "        'rejected': [\n",
        "            {'role': 'user', 'content': example['prompt']},\n",
        "            {'role': 'assistant', 'content': example['rejected']},\n",
        "        ],\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "4f7c44a5-82bf-4446-940a-e53bbd50d65d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-28T21:33:03.791070Z",
          "iopub.status.busy": "2025-03-28T21:33:03.790793Z",
          "iopub.status.idle": "2025-03-28T21:33:06.736362Z",
          "shell.execute_reply": "2025-03-28T21:33:06.735525Z",
          "shell.execute_reply.started": "2025-03-28T21:33:03.791050Z"
        },
        "id": "4f7c44a5-82bf-4446-940a-e53bbd50d65d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.map(to_implicit_prompt_preferences, remove_columns=[\"prompt\"])\n",
        "dataset = dataset.train_test_split(train_size=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "495a42f6-2acc-4382-84ad-444d689892a2",
      "metadata": {
        "id": "495a42f6-2acc-4382-84ad-444d689892a2"
      },
      "source": [
        "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±—É–¥–µ–º —Ç—É –∂–µ –º–æ–¥–µ–ª—å, –æ–±—É—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –ø–æ–≤–µ—Ä—Ö. –î–ª—è –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `AutoModelForSequenceClassification`. –û–±—É—á–∏—Ç–µ —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å `RewardConfig` –∏ `RewardTrainer`. –û–¥–Ω–æ–π —ç–ø–æ—Ö–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ (–¥–∞–∂–µ –º–µ–Ω—å—à–µ). –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –ø–æ–¥–≥—Ä—É–∑–∏—Ç–µ –ø–æ–ª—É—á–∏–≤—à—É—é—Å—è –º–æ–¥–µ–ª—å –Ω–∞ —Ö–∞–±."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5562eb-d49c-41c7-b9b6-8640da8c39dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-03-28T21:35:44.510927Z",
          "iopub.status.busy": "2025-03-28T21:35:44.510592Z",
          "iopub.status.idle": "2025-03-28T21:35:56.940848Z",
          "shell.execute_reply": "2025-03-28T21:35:56.939588Z",
          "shell.execute_reply.started": "2025-03-28T21:35:44.510903Z"
        },
        "id": "4d5562eb-d49c-41c7-b9b6-8640da8c39dc",
        "outputId": "366673d0-506c-48b2-8c56-2d432aa9dfdb",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceTB/SmolLM-135M-Instruct and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4895' max='4895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4895/4895 14:31, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.592700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.425600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.291100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.219100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.178600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.135900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.098900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.110800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.052800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.046800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.052300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.071500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.072200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.085000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.037400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.024900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.030700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.049300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.028400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>0.056700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.036000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>0.019600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.024900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>0.027200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.020600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.072200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>0.054500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.014900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.015200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>0.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.022700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.018600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.045100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>0.030500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>0.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.011700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>0.014500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>0.006200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.018700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>0.021200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.024700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>0.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>0.039800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.006200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>0.016900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.011200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>0.016300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2525</td>\n",
              "      <td>0.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2575</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2625</td>\n",
              "      <td>0.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.010900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2675</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2725</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2775</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2825</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.011200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2875</td>\n",
              "      <td>0.025700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2925</td>\n",
              "      <td>0.045500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2975</td>\n",
              "      <td>0.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3025</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3075</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3125</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3175</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3225</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3275</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.008000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3325</td>\n",
              "      <td>0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3375</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.015100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3425</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3475</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3525</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3575</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.009400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3625</td>\n",
              "      <td>0.075600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.023100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3675</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.012300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3725</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3775</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3825</td>\n",
              "      <td>0.033700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3875</td>\n",
              "      <td>0.027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3925</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3975</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4025</td>\n",
              "      <td>0.015200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4075</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4125</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.008700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4175</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4225</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4275</td>\n",
              "      <td>0.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4325</td>\n",
              "      <td>0.031300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4375</td>\n",
              "      <td>0.023200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4425</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4475</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4525</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4575</td>\n",
              "      <td>0.009600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4625</td>\n",
              "      <td>0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4675</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4725</td>\n",
              "      <td>0.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4775</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4825</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4875</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4895, training_loss=0.0253726896899348, metrics={'train_runtime': 872.0033, 'train_samples_per_second': 11.227, 'train_steps_per_second': 5.614, 'total_flos': 0.0, 'train_loss': 0.0253726896899348, 'epoch': 1.0})"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "# –í–∞–∂–Ω–æ, —á—Ç–æ–±—ã —Ç—Ä–µ–Ω–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏.\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# reward_model = todo()\n",
        "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    num_labels=1,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "for param in reward_model.parameters():\n",
        "    param.requires_grad = False\n",
        "reward_model.score.weight.requires_grad = True\n",
        "\n",
        "reward_model.train()\n",
        "reward_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "reward_config = RewardConfig(\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    max_length=1024,\n",
        "    disable_dropout=True,\n",
        "    learning_rate=3e-4,\n",
        "    seed=42,\n",
        "    logging_steps=25,\n",
        "    report_to=\"wandb\" if ENABLE_WANDB else \"none\",\n",
        "    output_dir=\"/kaggle/working/\"\n",
        ")\n",
        "reward_trainer = RewardTrainer(\n",
        "    model=reward_model,\n",
        "    processing_class=tokenizer,\n",
        "    args=reward_config,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        ")\n",
        "\n",
        "reward_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ePW1KF4e7GSt",
      "metadata": {
        "id": "ePW1KF4e7GSt"
      },
      "outputs": [],
      "source": [
        "# reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     f\"{REPO_NAME}-reward-model\",\n",
        "#     num_labels=1,\n",
        "#     attn_implementation=\"sdpa\",\n",
        "#     device_map=DEVICE,\n",
        "# )\n",
        "# reward_model = reward_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9af43201-f883-4399-9673-bca566decbc8",
      "metadata": {
        "id": "9af43201-f883-4399-9673-bca566decbc8"
      },
      "source": [
        "–ù–∞–≥—Ä–∞–¥–∞ –¥–ª—è chosen –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã—à–µ —á–µ–º –¥–ª—è rejected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "06962fb8-1cfb-4c0f-bf35-dda4fb2b4037",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-28T21:34:46.950068Z",
          "iopub.status.idle": "2025-03-28T21:34:46.950340Z",
          "shell.execute_reply": "2025-03-28T21:34:46.950216Z"
        },
        "id": "06962fb8-1cfb-4c0f-bf35-dda4fb2b4037",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "inputs_chosen = tokenizer.apply_chat_template(dataset[\"test\"][0][\"chosen\"], tokenize=False)\n",
        "inputs_chosen = tokenizer(inputs_chosen, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "inputs_rejected = tokenizer.apply_chat_template(dataset[\"test\"][0][\"rejected\"], tokenize=False)\n",
        "inputs_rejected = tokenizer(inputs_rejected, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "score_chosen = reward_model(**inputs_chosen).logits[0].cpu().detach()\n",
        "score_rejected = reward_model(**inputs_rejected).logits[0].cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "9e43f430-3a8c-4a07-bc6e-ab934963921d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-03-28T21:34:46.950966Z",
          "iopub.status.idle": "2025-03-28T21:34:46.951211Z",
          "shell.execute_reply": "2025-03-28T21:34:46.951114Z"
        },
        "id": "9e43f430-3a8c-4a07-bc6e-ab934963921d",
        "outputId": "84dd8809-7eef-4a3c-ba84-128bd05dc8be",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([5.3307]), tensor([-3.3285]))"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_chosen, score_rejected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "dec6bca3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "execution": {
          "iopub.status.busy": "2025-03-28T21:34:46.952040Z",
          "iopub.status.idle": "2025-03-28T21:34:46.952316Z",
          "shell.execute_reply": "2025-03-28T21:34:46.952180Z"
        },
        "id": "dec6bca3",
        "outputId": "80ac5696-5310-48b8-c51b-e3f343a8237f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Dayara13/llm-course-hw2-reward-model/commit/96938109ac7db543680bcae3601cd4e71c676b3e', commit_message='Upload LlamaForSequenceClassification', commit_description='', oid='96938109ac7db543680bcae3601cd4e71c676b3e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Dayara13/llm-course-hw2-reward-model', endpoint='https://huggingface.co', repo_type='model', repo_id='Dayara13/llm-course-hw2-reward-model'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∏–º reward –º–æ–¥–µ–ª—å –Ω–∞ —Ö–∞–±\n",
        "\n",
        "reward_model.push_to_hub(f\"{REPO_NAME}-reward-model\", dataset_name=DATASET_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c35fb9-2aac-408b-aff9-da6251dc7c0f",
      "metadata": {
        "id": "c4c35fb9-2aac-408b-aff9-da6251dc7c0f"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ PPO [4 –±–∞–ª–ª–∞]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b2e2a40-589b-42bf-bf15-bb10bb0e84cd",
      "metadata": {
        "id": "9b2e2a40-589b-42bf-bf15-bb10bb0e84cd"
      },
      "source": [
        "**WARN**: TRL –Ω–µ–¥–∞–≤–Ω–æ —Å–º–µ—Ä–∂–∏–ª–∏ –±–æ–ª—å—à–æ–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä PPO, –∑–∞–±—ã–≤ –æ–±–Ω–æ–≤–∏—Ç—å –≤—Å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏ –ø—Ä–∏–º–µ—Ä—ã ü•¥ü•¥ü•¥. –î–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å–º–æ—Ç—Ä–∏—Ç–µ –≤ –∫–æ–¥, –∞ –Ω–µ –≤ –¥–æ–∫–º–µ–Ω—Ç–∞—Ü–∏—é. –ï—Å–ª–∏ –≤–∞–º –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –∑–Ω–∞—Ç—å –≤–∏–Ω–æ–≤–Ω—ã—Ö –≤ –ª–∏—Ü–æ:\n",
        "\n",
        "<a href=\"https://ibb.co/zTFL4GTt\"><img src=\"https://i.ibb.co/1tMpm8t4/Screenshot-2025-02-13-at-17-40-48.png\" alt=\"\" border=\"0\" /></a>\n",
        "\n",
        "–î–ª—è PPO –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç, –Ω–æ —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Ç–æ–ª—å–∫–æ prompt. –ü—Ä–∏–≤–µ–¥–∏—Ç–µ prompt –≤ —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç –∏ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ (`tokenizer.apply_chat_template`). –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å.\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ `policy`, `ref_policy` –ø–æ–¥–≥—Ä—É–∑–∏—Ç–µ SmolLM2-135M-Instruct, –≤ –∫–∞—á–µ—Å—Ç–≤–µ `reward_model`, `value_model` —Å–≤–æ—é –æ–±—É—á–µ–Ω–Ω—É—é —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª—å. –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `PPOConfig` –∏ `PPOTrainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "de68e7e9-c107-46e8-b4f4-f0118af36036",
      "metadata": {
        "id": "de68e7e9-c107-46e8-b4f4-f0118af36036",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "RL_MODEL_ID = 'HuggingFaceTB/SmolLM2-135M-Instruct'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, padding_side=\"left\")\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "\n",
        "# value_model = todo()\n",
        "# reward_model = todo()\n",
        "# policy = todo()\n",
        "# ref_policy = todo()\n",
        "\n",
        "value_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    f\"{REPO_NAME}-reward-model\",\n",
        "    num_labels=1,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    f\"{REPO_NAME}-reward-model\",\n",
        "    num_labels=1,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "policy = AutoModelForCausalLM.from_pretrained(\n",
        "    RL_MODEL_ID,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "ref_policy = AutoModelForCausalLM.from_pretrained(\n",
        "    RL_MODEL_ID,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "\n",
        "def tokenize(example, tokenizer):\n",
        "    # input_ids = todo()\n",
        "    to_chat_template = [\n",
        "        {\"content\": example[\"prompt\"], \"role\": \"user\"},\n",
        "    ]\n",
        "    assistant_div = \"<|im_start|>assistant\\n\"\n",
        "    input_text = tokenizer.apply_chat_template(to_chat_template, tokenize=False)\n",
        "    input_text += assistant_div\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"][0]\n",
        "    return {\"input_ids\": input_ids}\n",
        "\n",
        "\n",
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.remove_columns([\"chosen\", \"rejected\"])\n",
        "dataset = dataset.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer}, remove_columns=dataset.column_names)\n",
        "dataset = dataset.train_test_split()\n",
        "\n",
        "# training_args = todo()\n",
        "# trainer = todo()\n",
        "\n",
        "training_args = PPOConfig(\n",
        "    num_train_epochs=1,\n",
        "    num_ppo_epochs=2,\n",
        "    per_device_train_batch_size=64,\n",
        "    learning_rate=5e-5,\n",
        "    seed=42,\n",
        "    logging_steps=50,\n",
        "    response_length=100,\n",
        "    kl_coef=1.0,\n",
        "    cliprange=0.2,\n",
        "    vf_coef=0.3,\n",
        "    gradient_accumulation_steps=1,\n",
        "    save_steps=0,\n",
        "    output_dir=None,\n",
        ")\n",
        "\n",
        "class NoSavePPOTrainer(PPOTrainer):\n",
        "    def save_model(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def _save_checkpoint(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "trainer = NoSavePPOTrainer(\n",
        "    args=training_args,\n",
        "    processing_class=tokenizer,\n",
        "    model=policy,\n",
        "    ref_model=ref_policy,\n",
        "    reward_model=reward_model,\n",
        "    value_model=value_model,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['test'],\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fE0rHUx7AO_4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE0rHUx7AO_4",
        "outputId": "a038316f-2d9e-42d0-ade1-b41ee16fbc6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# policy.load_state_dict(\n",
        "#     torch.load(\"/content/drive/MyDrive/ppo_2.pth\", weights_only=True, map_location=DEVICE)\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abeaee5e-8429-48bf-a35b-3addfdb10efb",
      "metadata": {
        "id": "abeaee5e-8429-48bf-a35b-3addfdb10efb"
      },
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–∞—Ö. –í–ø–æ–ª–Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ, —á—Ç–æ –≤—ã –Ω–µ —É–≤–∏–¥–∏—Ç–µ —Ç–∞–∫–æ–≥–æ —Å–∏–ª—å–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞–∫ –ø–æ—Å–ª–µ DPO. PPO —Ç—Ä–µ–±—É–µ—Ç –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤, –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤ —Ü–µ–ª–æ–º –Ω–µ —Ç–∞–∫ —Å—Ç–∞–±–∏–ª–µ–Ω."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5f399f65-81f2-4867-a776-09be56d4f7e1",
      "metadata": {
        "id": "5f399f65-81f2-4867-a776-09be56d4f7e1"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "generated_ids = policy.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "init_generated_ids = ref_policy.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "init_response = tokenizer.batch_decode(init_generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2c0e3a60-02b6-4e2c-828c-7837472f60c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c0e3a60-02b6-4e2c-828c-7837472f60c4",
        "outputId": "e40de0c1-95a2-4496-b21a-6abf17fa48ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======== BEFORE TUNING ========\n",
            "user\n",
            "What's your morning routine like?\n",
            "assistant\n",
            "My morning routine is a bit unconventional, but it's been a labor of love for me. I wake up before the sun rises, around 6:30 am. I head to the kitchen, where I fire up the coffee machine and start brewing a cup of coffee. I like to start my day with a cup of coffee, and I like to make it a ritual.\n",
            "\n",
            "After brewing, I head to the gym, where I do a few sets of push-ups, squats, and lunges. I like to get some fresh air and get my blood flowing. I also like to do some stretching exercises, like leg raises and shoulder stretches, to help my muscles recover.\n",
            "\n",
            "After my workout, I head to the kitchen to grab a quick breakfast. I usually grab a bagel or a cup of coffee, and then head to the office to get ready for the day. I like to get a good night's sleep, and I like to make sure I have a good cup of coffee and a healthy breakfast.\n",
            "\n",
            "I also like to take a short walk around the block, just to clear my head and get some fresh air. I like to do some stretching exercises, like leg raises and shoulder stretches, to help my muscles recover\n",
            "\n",
            "======== AFTER TUNING ========\n",
            "user\n",
            "What's your morning routine like?\n",
            "assistant\n",
            "My morning routine is always a challenge, but it's a great way to get started. I like to wake up early, around 6:30 am, and make sure I have everything I need for the day. I usually start by getting a cup of coffee or tea, and then head to the kitchen to make a cup of coffee myself.\n",
            "\n",
            "After that, I head to the gym for a quick workout to get my blood pumping. I love working out in the morning, because it gives me a chance to clear my head and get into a rhythm. I also like to get some fresh air and exercise to help me feel more energized and focused.\n",
            "\n",
            "After that, I head to the kitchen to make some breakfast. I usually make scrambled eggs, toast, and a fruit salad. I love the combination of the morning routine and the breakfast.\n",
            "\n",
            "Once I've got my morning routine in place, I head to the gym again to do some cardio. I love working out in the morning, because it gives me a chance to clear my head and get into a rhythm. I also like to get some fresh air and exercise to help me feel more energized and focused.\n",
            "\n",
            "After that, I head to the kitchen to make some dinner. I\n"
          ]
        }
      ],
      "source": [
        "print(\"======== BEFORE TUNING ========\")\n",
        "print(init_response)\n",
        "print()\n",
        "\n",
        "print(\"======== AFTER TUNING ========\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e5424c50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "cd288ba39d1e4d2596009fc29fbe7908",
            "ffe85fc3bfba409abc9913d93bb68c6f",
            "af9a3656dfa042e687289dbd0d579b9a",
            "ba1a2c70f09a4040a4b6174d7443b2e4",
            "936a362609c342a695a5b30a9c4f2433",
            "f28c4f6cb251429a92ba45a754cbbb9c",
            "9e652e052e5d43b18e98aca889f5e590",
            "72985388320e4a2cbe1751bec60eb47c",
            "cffde7da581e42e396da703e93ebbd45",
            "425c2f4b1cbf4a95b85825d25692ebf9",
            "1751fd0981d94e5d8d163bd80e71a6c4"
          ]
        },
        "id": "e5424c50",
        "outputId": "988b0e70-fec4-4f17-de64-af6853c8d74f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd288ba39d1e4d2596009fc29fbe7908",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Dayara13/llm-course-hw2-ppo/commit/561563ab30e590e599ba72ca0efd852f86dfd5c9', commit_message='Upload tokenizer', commit_description='', oid='561563ab30e590e599ba72ca0efd852f86dfd5c9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Dayara13/llm-course-hw2-ppo', endpoint='https://huggingface.co', repo_type='model', repo_id='Dayara13/llm-course-hw2-ppo'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞ —Ö–∞–±\n",
        "\n",
        "policy.push_to_hub(f\"{REPO_NAME}-ppo\")\n",
        "tokenizer.push_to_hub(f\"{REPO_NAME}-ppo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4c547e-f9e7-42c4-acb4-513853326e76",
      "metadata": {
        "id": "6b4c547e-f9e7-42c4-acb4-513853326e76"
      },
      "source": [
        "## –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏ [2 –±–∞–ª–ª]\n",
        "\n",
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–æ–¥–µ–ª—å (–æ—Ç DPO –∏ PPO).\n",
        "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ª–æ–≥–ø—Ä–æ–± –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –∏ —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª–∞.\n",
        "–ü–æ–¥–æ–π–¥–µ—Ç –ª—é–±–æ–π –Ω–µ —Å–∏–ª—å–Ω–æ –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç —Å hugging face.\n",
        "\n",
        "–°—á–∏—Ç–∞–µ—Ç –ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1356ece6-c7d5-4431-8558-5be5908d8654",
      "metadata": {
        "id": "1356ece6-c7d5-4431-8558-5be5908d8654"
      },
      "outputs": [],
      "source": [
        "todo()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b84b1b",
      "metadata": {
        "id": "69b84b1b"
      },
      "source": [
        "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã\n",
        "\n",
        "–í—ã —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã:\n",
        "- –û—Ñ–æ—Ä–º–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–∞ ü§ó (–º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å 3 —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è): –∫–∞—Ä—Ç–æ—á–∫–∞ –º–æ–¥–µ–ª–∏ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∑–∞–¥–∞–Ω–∏—è, —Ä–µ–ø–æ—Ä—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ **[2 –±–∞–ª–ª–∞]**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37de87c4",
      "metadata": {
        "id": "37de87c4"
      },
      "source": [
        "# –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä—è—é—â–µ–≥–æ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a0c0c7",
      "metadata": {
        "id": "33a0c0c7"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "DPO_REPO_NAME = f\"{REPO_NAME}-dpo\"\n",
        "PPO_REPO_NAME = f\"{REPO_NAME}-ppo\"\n",
        "REWARD_MODEL_REPO_NAME = f\"{REPO_NAME}-reward-model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(DPO_REPO_NAME)\n",
        "check_model = AutoModelForCausalLM.from_pretrained(DPO_REPO_NAME)\n",
        "check_model = check_model.to(device)\n",
        "check_model = check_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7605867",
      "metadata": {
        "id": "c7605867"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = check_model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "response = tokenizer.decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 6993014,
          "sourceId": 11200236,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6993092,
          "sourceId": 11200353,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0596c4d9027d4f2aa0f14d70897ad910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63ce064f8e6a46c69856b653666a9aeb",
              "IPY_MODEL_4fd37ec07a1f4d72bdbe63086986b3bc",
              "IPY_MODEL_2c4a5bb04b414658a2085d7f56e23865"
            ],
            "layout": "IPY_MODEL_59fbd435254a425c8a792dc909caa6e8"
          }
        },
        "114db4aa577f4d23b2c30847006340db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaf3d8a949884c649130fc3220be6748",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8b9482c396a8479f9ec094816c3cabe9",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "1751fd0981d94e5d8d163bd80e71a6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "204e99217541433dafd010ffc1fca2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6751043e2d6f48baa3a402b7c5ffb596",
              "IPY_MODEL_89b9c031423c4cce9ccdf49649882b99",
              "IPY_MODEL_3cca63a666244c83b2db19acaa44c237"
            ],
            "layout": "IPY_MODEL_90c8b4a0792e45d7ba586a6ad90e916b"
          }
        },
        "21d50ddc66974db5b1edf22067069f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2738269baa104c0886d922932f3dc90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d50ddc66974db5b1edf22067069f7a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b0ffc310a2a64d428612aa833e985734",
            "value": "‚Äá156/156‚Äá[00:00&lt;00:00,‚Äá5.71kB/s]"
          }
        },
        "2c4a5bb04b414658a2085d7f56e23865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d4265b3704442eab0cbced7e25d259",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ab4cbbc7b77947009245733852b40a07",
            "value": "‚Äá723/723‚Äá[00:00&lt;00:00,‚Äá20.3kB/s]"
          }
        },
        "2e7b1e44afaa4da5be8643b50b7986fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3619eb7631c54c2faec9eda3fe808777": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6bbe0d878c84fb4a2e7f2bf569b0b4b",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_491030b3b886455a90cdb3158c6722f6",
            "value": 156
          }
        },
        "37d07433786e41f5afba715893035f86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cca63a666244c83b2db19acaa44c237": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba52c87ce3945a9b54d15ea562cab2c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_834884ef14c64709aa4d77e1e351624f",
            "value": "‚Äá269M/269M‚Äá[00:02&lt;00:00,‚Äá151MB/s]"
          }
        },
        "425c2f4b1cbf4a95b85825d25692ebf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491030b3b886455a90cdb3158c6722f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fd37ec07a1f4d72bdbe63086986b3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7b1e44afaa4da5be8643b50b7986fe",
            "max": 723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_952d00751b7d4f4a92a63cc16b1d3f91",
            "value": 723
          }
        },
        "52dc77a77b0949a0b72b125d55fde10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_114db4aa577f4d23b2c30847006340db",
              "IPY_MODEL_3619eb7631c54c2faec9eda3fe808777",
              "IPY_MODEL_2738269baa104c0886d922932f3dc90f"
            ],
            "layout": "IPY_MODEL_a3512a7c182c429aab4ad6c24024412b"
          }
        },
        "5632118a3b7941e0a7bd10a49174442f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59fbd435254a425c8a792dc909caa6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ce064f8e6a46c69856b653666a9aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e272d30b3d4942a786fa20eb48b4ecd7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9af977c16e9847078b66c471b161c5ab",
            "value": "config.json:‚Äá100%"
          }
        },
        "6751043e2d6f48baa3a402b7c5ffb596": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37d07433786e41f5afba715893035f86",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cf265f9ed1f546a291e853de114d2ea1",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "72985388320e4a2cbe1751bec60eb47c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834884ef14c64709aa4d77e1e351624f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89b9c031423c4cce9ccdf49649882b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5632118a3b7941e0a7bd10a49174442f",
            "max": 269060552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c9114abb4e64222832f6143663ea785",
            "value": 269060552
          }
        },
        "8b9482c396a8479f9ec094816c3cabe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c9114abb4e64222832f6143663ea785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90c8b4a0792e45d7ba586a6ad90e916b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936a362609c342a695a5b30a9c4f2433": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952d00751b7d4f4a92a63cc16b1d3f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9af977c16e9847078b66c471b161c5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e652e052e5d43b18e98aca889f5e590": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3512a7c182c429aab4ad6c24024412b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf3d8a949884c649130fc3220be6748": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab4cbbc7b77947009245733852b40a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af9a3656dfa042e687289dbd0d579b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72985388320e4a2cbe1751bec60eb47c",
            "max": 5174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cffde7da581e42e396da703e93ebbd45",
            "value": 5174
          }
        },
        "b0ffc310a2a64d428612aa833e985734": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba1a2c70f09a4040a4b6174d7443b2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425c2f4b1cbf4a95b85825d25692ebf9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1751fd0981d94e5d8d163bd80e71a6c4",
            "value": "‚Äá5.17k/5.17k‚Äá[00:00&lt;00:00,‚Äá239kB/s]"
          }
        },
        "bba52c87ce3945a9b54d15ea562cab2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd288ba39d1e4d2596009fc29fbe7908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffe85fc3bfba409abc9913d93bb68c6f",
              "IPY_MODEL_af9a3656dfa042e687289dbd0d579b9a",
              "IPY_MODEL_ba1a2c70f09a4040a4b6174d7443b2e4"
            ],
            "layout": "IPY_MODEL_936a362609c342a695a5b30a9c4f2433"
          }
        },
        "cf265f9ed1f546a291e853de114d2ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cffde7da581e42e396da703e93ebbd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6bbe0d878c84fb4a2e7f2bf569b0b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e272d30b3d4942a786fa20eb48b4ecd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28c4f6cb251429a92ba45a754cbbb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d4265b3704442eab0cbced7e25d259": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe85fc3bfba409abc9913d93bb68c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28c4f6cb251429a92ba45a754cbbb9c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9e652e052e5d43b18e98aca889f5e590",
            "value": "README.md:‚Äá100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
